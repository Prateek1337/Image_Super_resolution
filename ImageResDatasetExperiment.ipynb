{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageResDatasetExperiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prateek1337/Image_Super_resolution/blob/master/ImageResDatasetExperiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTLHSmW23asG",
        "colab_type": "code",
        "outputId": "9f59eab0-9305-43c4-edeb-e5f63ecc65d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "butterfly.png\t __pycache__\t\t   SRCNN_check955.h5\n",
            "face.png\t SRCNN_check915.h5\t   testFinal.h5\n",
            "louvre.png\t SRCNN_check935BSDS200.h5  test.h5\n",
            "ppExp.jpg\t SRCNN_check935G100.h5\t   trainFinalBSDS200.h5\n",
            "pp.jpg\t\t SRCNN_check935.h5\t   trainFinalG100.h5\n",
            "prepare_data.py  SRCNN_check935T91.h5\t   trainFinalT91.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV7UDX6B3q7P",
        "colab_type": "code",
        "outputId": "d9b30b4c-a437-40ae-ef43-221ce17f74d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "import os \n",
        "os.chdir(\"/content/drive/My Drive/Image_Resolution/\")\n",
        "os.getcwd()\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "butterfly.png\t __pycache__\t\t   SRCNN_check955.h5\n",
            "face.png\t SRCNN_check915.h5\t   testFinal.h5\n",
            "louvre.png\t SRCNN_check935BSDS200.h5  test.h5\n",
            "ppExp.jpg\t SRCNN_check935G100.h5\t   trainFinalBSDS200.h5\n",
            "pp.jpg\t\t SRCNN_check935.h5\t   trainFinalG100.h5\n",
            "prepare_data.py  SRCNN_check935T91.h5\t   trainFinalT91.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk6-ZqmZ4bTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import initializers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Input, BatchNormalization\n",
        "# from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.callbacks import ModelCheckpoint,Callback\n",
        "from keras.optimizers import SGD, Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import prepare_data as pd\n",
        "import numpy \n",
        "import math\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ninR1LjWtT29",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#setting seed for uniform results\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG0RN41fY1pk",
        "colab_type": "code",
        "outputId": "a36a1210-4874-4d27-fbf6-3dc14d5e371b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data_Y, label_Y = pd.read_training_data(\"./test.h5\")\n",
        "print(data_Y.shape,label_Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(420, 32, 32, 1) (420, 20, 20, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g-jFwan61pN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#9-1-5 Architecture \n",
        "def model915():\n",
        "    # lrelu = LeakyReLU(alpha=0.1)\n",
        "    SRCNN = Sequential()\n",
        "    SRCNN.add(Conv2D(nb_filter=128, nb_row=9, nb_col=9, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='valid', bias=True, input_shape=(32, 32, 1)))\n",
        "    SRCNN.add(Conv2D(nb_filter=64, nb_row=1, nb_col=1, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='same', bias=True))\n",
        "    # SRCNN.add(BatchNormalization())\n",
        "    SRCNN.add(Conv2D(nb_filter=1, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='linear', border_mode='valid', bias=True))\n",
        "    adam = Adam(lr=0.0003)\n",
        "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return SRCNN\n",
        "def predict_model915():\n",
        "    # lrelu = LeakyReLU(alpha=0.1)\n",
        "    SRCNN = Sequential()\n",
        "    SRCNN.add(Conv2D(nb_filter=128, nb_row=9, nb_col=9, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='valid', bias=True, input_shape=(None, None, 1)))\n",
        "    SRCNN.add(Conv2D(nb_filter=64, nb_row=1, nb_col=1, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='same', bias=True))\n",
        "    # SRCNN.add(BatchNormalization())\n",
        "    SRCNN.add(Conv2D(nb_filter=1, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='linear', border_mode='valid', bias=True))\n",
        "    adam = Adam(lr=0.0003)\n",
        "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return SRCNN\n",
        "\n",
        " \n",
        " \n",
        "#9-3-5 Architecture \n",
        "def model935():\n",
        "    # lrelu = LeakyReLU(alpha=0.1)\n",
        "    SRCNN = Sequential()\n",
        "    SRCNN.add(Conv2D(nb_filter=128, nb_row=9, nb_col=9, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='valid', bias=True, input_shape=(32, 32, 1)))\n",
        "    SRCNN.add(Conv2D(nb_filter=64, nb_row=3, nb_col=3, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='same', bias=True))\n",
        "    # SRCNN.add(BatchNormalization())\n",
        "    SRCNN.add(Conv2D(nb_filter=1, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='linear', border_mode='valid', bias=True))\n",
        "    adam = Adam(lr=0.0003)\n",
        "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return SRCNN\n",
        "def predict_model935():\n",
        "    # lrelu = LeakyReLU(alpha=0.1)\n",
        "    SRCNN = Sequential()\n",
        "    SRCNN.add(Conv2D(nb_filter=128, nb_row=9, nb_col=9, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='valid', bias=True, input_shape=(None, None, 1)))\n",
        "    SRCNN.add(Conv2D(nb_filter=64, nb_row=3, nb_col=3, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='same', bias=True))\n",
        "    # SRCNN.add(BatchNormalization())\n",
        "    SRCNN.add(Conv2D(nb_filter=1, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='linear', border_mode='valid', bias=True))\n",
        "    adam = Adam(lr=0.0003)\n",
        "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return SRCNN\n",
        "\n",
        "\n",
        " \n",
        "#9-5-5 Architecture \n",
        "def model955():\n",
        "    # lrelu = LeakyReLU(alpha=0.1)\n",
        "    SRCNN = Sequential()\n",
        "    SRCNN.add(Conv2D(nb_filter=128, nb_row=9, nb_col=9, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='valid', bias=True, input_shape=(32, 32, 1)))\n",
        "    SRCNN.add(Conv2D(nb_filter=64, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='same', bias=True))\n",
        "    # SRCNN.add(BatchNormalization())\n",
        "    SRCNN.add(Conv2D(nb_filter=1, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='linear', border_mode='valid', bias=True))\n",
        "    adam = Adam(lr=0.0003)\n",
        "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return SRCNN\n",
        "def predict_model955():\n",
        "    # lrelu = LeakyReLU(alpha=0.1)\n",
        "    SRCNN = Sequential()\n",
        "    SRCNN.add(Conv2D(nb_filter=128, nb_row=9, nb_col=9, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='valid', bias=True, input_shape=(None, None, 1)))\n",
        "    SRCNN.add(Conv2D(nb_filter=64, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='same', bias=True))\n",
        "    # SRCNN.add(BatchNormalization())\n",
        "    SRCNN.add(Conv2D(nb_filter=1, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='linear', border_mode='valid', bias=True))\n",
        "    adam = Adam(lr=0.0003)\n",
        "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return SRCNN\n",
        "\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOy6MsaDj1KS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def psnr(target, ref):\n",
        "    mse = numpy.mean( (target - ref) ** 2 )\n",
        "    PIXEL_MAX = 255.0\n",
        "    if mse == 0:\n",
        "        return 100\n",
        "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
        "\n",
        "\n",
        "\n",
        "class PsnrHistory(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.psnrs = []\n",
        "        \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        global modelArc\n",
        "        global ds\n",
        "        if modelArc==\"955\":\n",
        "          srcnn_model=predict_model955()\n",
        "          weights_file=\"SRCNN_check955.h5\"\n",
        "        elif modelArc==\"935\":\n",
        "          srcnn_model=predict_model935()\n",
        "          weights_file=\"SRCNN_check935\"+ds+\".h5\"\n",
        "        elif modelArc==\"915\":\n",
        "          srcnn_model=predict_model915()\n",
        "          weights_file=\"SRCNN_check915.h5\"\n",
        "        srcnn_model.load_weights(weights_file)\n",
        "        avg_psnr=0.0\n",
        "        import cv2\n",
        "        for i in range(0,data_Y.shape[0]):\n",
        "            img=data_Y[i]\n",
        "            Y = numpy.zeros((1, img.shape[0], img.shape[1], 1), dtype=float)\n",
        "            Y[0, :, :, :] = img\n",
        "            pre = srcnn_model.predict(Y, batch_size=1) * 255.\n",
        "            pre[pre[:] > 255] = 255\n",
        "            pre[pre[:] < 0] = 0\n",
        "            img_pre=pre[0,:,:,:]\n",
        "            avg_psnr=avg_psnr+psnr(label_Y[i]*255, img_pre)\n",
        "\n",
        "        avg_psnr=(avg_psnr/data_Y.shape[0])\n",
        "        \n",
        "        self.psnrs.append((avg_psnr))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhRytvFCm-Eq",
        "colab_type": "code",
        "outputId": "c3b5982b-bce4-43d1-9e50-0dec77a854ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#TPU EXPERIMENTATION TRY LATER\n",
        "try:\n",
        "  device_name = os.environ['COLAB_TPU_ADDR']\n",
        "  TPU_ADDRESS = 'grpc://' + device_name\n",
        "  print('Found TPU at: {}'.format(TPU_ADDRESS))\n",
        "\n",
        "except KeyError:\n",
        "  print('TPU not found')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy9tcl-clzp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TPU EXPERIMENTATION TRY LATER\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "tpu_model915 = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model915,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(\n",
        "            tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "    )\n",
        ")\n",
        "tpu_model935 = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model935,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(\n",
        "            tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "    )\n",
        ")\n",
        "tpu_model955 = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model955,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(\n",
        "            tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "    )\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBbPfb1Zj2ha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(history,arch,dst):\n",
        "    \n",
        "    if arch==\"915\":\n",
        "      srcnn_model = model915()\n",
        "    elif arch==\"935\":\n",
        "      srcnn_model=model935()\n",
        "      \n",
        "    else:\n",
        "      srcnn_model=model955()\n",
        "    dfile=\"./trainFinal\"+dst+\".h5\"\n",
        "    print(srcnn_model.summary(),dfile,arch,sep=\"\\n\\n\")\n",
        "    data, label = pd.read_training_data(dfile)\n",
        "    val_data, val_label = pd.read_training_data(\"./test.h5\")\n",
        "    global modelArc\n",
        "    global ds\n",
        "    ds=dst\n",
        "    modelArc=arch\n",
        "    h5File=\"SRCNN_check\"+arch+dst+\".h5\"\n",
        "    checkpoint = ModelCheckpoint(h5File, monitor='val_loss', verbose=1, save_best_only=True,\n",
        "                                 save_weights_only=False, mode='min')\n",
        "    callbacks_list = [checkpoint,history]\n",
        "\n",
        "    srcnn_model.fit(data, label, batch_size=128, validation_data=(val_data, val_label),\n",
        "                    callbacks=callbacks_list, shuffle=True, nb_epoch=200, verbose=0)\n",
        "    # srcnn_model.load_weights(\"m_model_adam.h5\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKoQW_rynI_2",
        "colab_type": "code",
        "outputId": "45d40980-899c-4553-ad50-c5b2d6a8518f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "historyG100=PsnrHistory()\n",
        "train(historyG100,\"935\",\"G100\")\n",
        "print(\"Final Psnr:\",historyG100.psnrs[-1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(32, 32, 1..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(3, 3), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_56\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_166 (Conv2D)          (None, 24, 24, 128)       10496     \n",
            "_________________________________________________________________\n",
            "conv2d_167 (Conv2D)          (None, 24, 24, 64)        73792     \n",
            "_________________________________________________________________\n",
            "conv2d_168 (Conv2D)          (None, 20, 20, 1)         1601      \n",
            "=================================================================\n",
            "Total params: 85,889\n",
            "Trainable params: 85,889\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "./trainFinalG100.h5\n",
            "\n",
            "935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.00143, saving model to SRCNN_check935G100.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(None, Non..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(3, 3), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00002: val_loss improved from 0.00143 to 0.00136, saving model to SRCNN_check935G100.h5\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.00136 to 0.00135, saving model to SRCNN_check935G100.h5\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.00135 to 0.00132, saving model to SRCNN_check935G100.h5\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00132 to 0.00130, saving model to SRCNN_check935G100.h5\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00130 to 0.00128, saving model to SRCNN_check935G100.h5\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00128 to 0.00125, saving model to SRCNN_check935G100.h5\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00125 to 0.00124, saving model to SRCNN_check935G100.h5\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00124 to 0.00124, saving model to SRCNN_check935G100.h5\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00124 to 0.00123, saving model to SRCNN_check935G100.h5\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00123 to 0.00123, saving model to SRCNN_check935G100.h5\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.00123 to 0.00122, saving model to SRCNN_check935G100.h5\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.00122 to 0.00121, saving model to SRCNN_check935G100.h5\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.00121 to 0.00121, saving model to SRCNN_check935G100.h5\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.00121 to 0.00120, saving model to SRCNN_check935G100.h5\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.00120 to 0.00120, saving model to SRCNN_check935G100.h5\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.00120 to 0.00120, saving model to SRCNN_check935G100.h5\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.00120 to 0.00120, saving model to SRCNN_check935G100.h5\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.00120 to 0.00119, saving model to SRCNN_check935G100.h5\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00069: val_loss improved from 0.00119 to 0.00119, saving model to SRCNN_check935G100.h5\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.00119\n",
            "Final Psnr: 33.6043754231407\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAJr8VdLaqjC",
        "colab_type": "code",
        "outputId": "71d0d086-604e-4676-d008-426c95a3e9a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "historyT91=PsnrHistory()\n",
        "\n",
        "\n",
        "train(historyT91,\"935\",\"T91\")\n",
        "print(\"Final Psnr:\",historyT91.psnrs[-1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_257\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_769 (Conv2D)          (None, 24, 24, 128)       10496     \n",
            "_________________________________________________________________\n",
            "conv2d_770 (Conv2D)          (None, 24, 24, 64)        73792     \n",
            "_________________________________________________________________\n",
            "conv2d_771 (Conv2D)          (None, 20, 20, 1)         1601      \n",
            "=================================================================\n",
            "Total params: 85,889\n",
            "Trainable params: 85,889\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "./trainFinalT91.h5\n",
            "\n",
            "935"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(32, 32, 1..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(3, 3), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.00259, saving model to SRCNN_check935T91.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(None, Non..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(3, 3), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00002: val_loss improved from 0.00259 to 0.00169, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.00169 to 0.00151, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.00151 to 0.00144, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00144 to 0.00141, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00141 to 0.00140, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00140 to 0.00138, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00138 to 0.00136, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.00136\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00136 to 0.00136, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00136 to 0.00135, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00135 to 0.00134, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00134 to 0.00134, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.00134\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00134 to 0.00133, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00133\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.00133\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00133 to 0.00132, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00132 to 0.00131, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00131 to 0.00129, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.00129 to 0.00128, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.00128 to 0.00126, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.00126 to 0.00125, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.00125 to 0.00124, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.00124 to 0.00124, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00051: val_loss improved from 0.00124 to 0.00124, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.00124 to 0.00123, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.00123 to 0.00123, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00070: val_loss improved from 0.00123 to 0.00123, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00073: val_loss improved from 0.00123 to 0.00122, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00081: val_loss improved from 0.00122 to 0.00121, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00090: val_loss improved from 0.00121 to 0.00121, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00094: val_loss improved from 0.00121 to 0.00121, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00096: val_loss improved from 0.00121 to 0.00121, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00104: val_loss improved from 0.00121 to 0.00121, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00107: val_loss improved from 0.00121 to 0.00121, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00109: val_loss improved from 0.00121 to 0.00120, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00111: val_loss improved from 0.00120 to 0.00120, saving model to SRCNN_check935T91.h5\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.00120\n",
            "Final Psnr: 33.675175395988404\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXN5W5dsjwcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSiTc-iparFv",
        "colab_type": "code",
        "outputId": "9064da34-6b56-4393-a820-9365ca4e3e03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "historyBSDS200=PsnrHistory()\n",
        "\n",
        "\n",
        "train(historyBSDS200,\"935\",\"BSDS200\")\n",
        "print(\"Final Psnr:\",historyBSDS200.psnrs[-1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_458\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1372 (Conv2D)         (None, 24, 24, 128)       10496     \n",
            "_________________________________________________________________\n",
            "conv2d_1373 (Conv2D)         (None, 24, 24, 64)        73792     \n",
            "_________________________________________________________________\n",
            "conv2d_1374 (Conv2D)         (None, 20, 20, 1)         1601      \n",
            "=================================================================\n",
            "Total params: 85,889\n",
            "Trainable params: 85,889\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "./trainFinalBSDS200.h5\n",
            "\n",
            "935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(32, 32, 1..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(3, 3), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.00152, saving model to SRCNN_check935BSDS200.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(None, Non..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(3, 3), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00002: val_loss improved from 0.00152 to 0.00142, saving model to SRCNN_check935BSDS200.h5\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.00142 to 0.00139, saving model to SRCNN_check935BSDS200.h5\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.00139 to 0.00139, saving model to SRCNN_check935BSDS200.h5\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00139 to 0.00137, saving model to SRCNN_check935BSDS200.h5\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00137 to 0.00135, saving model to SRCNN_check935BSDS200.h5\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00135 to 0.00134, saving model to SRCNN_check935BSDS200.h5\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00134 to 0.00129, saving model to SRCNN_check935BSDS200.h5\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00129 to 0.00127, saving model to SRCNN_check935BSDS200.h5\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00127 to 0.00126, saving model to SRCNN_check935BSDS200.h5\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00126 to 0.00125, saving model to SRCNN_check935BSDS200.h5\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00125 to 0.00124, saving model to SRCNN_check935BSDS200.h5\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00124 to 0.00121, saving model to SRCNN_check935BSDS200.h5\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.00121 to 0.00121, saving model to SRCNN_check935BSDS200.h5\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.00121 to 0.00120, saving model to SRCNN_check935BSDS200.h5\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.00120 to 0.00120, saving model to SRCNN_check935BSDS200.h5\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.00120 to 0.00120, saving model to SRCNN_check935BSDS200.h5\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.00120 to 0.00120, saving model to SRCNN_check935BSDS200.h5\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.00120 to 0.00119, saving model to SRCNN_check935BSDS200.h5\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.00119 to 0.00119, saving model to SRCNN_check935BSDS200.h5\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00055: val_loss improved from 0.00119 to 0.00118, saving model to SRCNN_check935BSDS200.h5\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.00118\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.00118\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.00118\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.00118\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.00118\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.00118\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.00118 to 0.00118, saving model to SRCNN_check935BSDS200.h5\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.00118\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.00118\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.00118\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.00118\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.00118\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.00118\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.00118\n",
            "\n",
            "Epoch 00070: val_loss improved from 0.00118 to 0.00118, saving model to SRCNN_check935BSDS200.h5\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.00118\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.00118\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.00118\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.00118\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.00118\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.00118\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.00118\n",
            "\n",
            "Epoch 00078: val_loss improved from 0.00118 to 0.00117, saving model to SRCNN_check935BSDS200.h5\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00092: val_loss improved from 0.00117 to 0.00117, saving model to SRCNN_check935BSDS200.h5\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.00117\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.00117\n",
            "Final Psnr: 33.809924507466796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU4Y1ywhlAot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(architecture,file_name,dst):\n",
        "    if architecture==\"915\":\n",
        "      srcnn_model = predict_model915()\n",
        "    elif architecture==\"935\":\n",
        "      srcnn_model=predict_model935()\n",
        "    else:\n",
        "      srcnn_model=predict_model955()\n",
        "    weight_file=\"SRCNN_check\"+architecture+dst+\".h5\" \n",
        "    srcnn_model.load_weights(weight_file)\n",
        "    IMG_NAME = file_name\n",
        "    INPUT_NAME = \"Input to the \"+architecture+\"_\"+dst+\".png\"\n",
        "    OUTPUT_NAME = \"Output of the\"+architecture+\"_\"+dst+\".png\"\n",
        "\n",
        "    import cv2\n",
        "    img = cv2.imread(IMG_NAME, cv2.IMREAD_COLOR)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
        "    shape = img.shape\n",
        "    Y_img = cv2.resize(img[:, :, 0], (int(shape[1] / 2), int(shape[0] / 2)), cv2.INTER_CUBIC)\n",
        "    Y_img = cv2.resize(Y_img, (shape[1], shape[0]), cv2.INTER_CUBIC)\n",
        "    print(img.shape,Y_img.shape)\n",
        "    img[:, :, 0] = Y_img\n",
        "    Y_img=img[:,:,0]\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_YCrCb2BGR)\n",
        "    cv2.imwrite(INPUT_NAME, img)\n",
        "\n",
        "    Y = numpy.zeros((1, img.shape[0], img.shape[1], 1), dtype=float)\n",
        "    Y[0, :, :, 0] = Y_img.astype(float) / 255.\n",
        "    pre = srcnn_model.predict(Y, batch_size=1) * 255.\n",
        "    print(pre.shape)\n",
        "    pre[pre[:] > 255] = 255\n",
        "    pre[pre[:] < 0] = 0\n",
        "    pre = pre.astype(numpy.uint8)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
        "    img[6: -6, 6: -6, 0] = pre[0, :, :, 0]\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_YCrCb2BGR)\n",
        "    print(img.shape)\n",
        "    cv2.imwrite(OUTPUT_NAME, img)\n",
        "\n",
        "    # psnr calculation:\n",
        "    im1_rgb = cv2.imread(IMG_NAME, cv2.IMREAD_COLOR)[6: -6, 6: -6, :]\n",
        "    im1_Y = cv2.cvtColor(im1_rgb, cv2.COLOR_BGR2YCrCb)\n",
        "    im2_rgb = cv2.imread(INPUT_NAME, cv2.IMREAD_COLOR)[6: -6, 6: -6, :]\n",
        "    im2_Y = cv2.cvtColor(im2_rgb, cv2.COLOR_BGR2YCrCb)\n",
        "    im3_rgb = cv2.imread(OUTPUT_NAME, cv2.IMREAD_COLOR)[6: -6, 6: -6, :]\n",
        "    im3_Y = cv2.cvtColor(im3_rgb, cv2.COLOR_BGR2YCrCb)\n",
        "    print(im3_Y.shape,im1_Y.shape)\n",
        "    print(\"bicubic:\")\n",
        "    print(\"YCrCCb= {} , RGB={}\".format(psnr(im1_Y[:,:,0],im2_Y[:,:,0]),psnr(im1_rgb,im2_rgb)))\n",
        "    print(\"SRCNN:\")\n",
        "    print(\"YCrCCb= {} , RGB={}\".format(psnr(im1_Y[:,:,0],im3_Y[:,:,0]),psnr(im1_rgb,im3_rgb)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87FeW85u8L7c",
        "colab_type": "code",
        "outputId": "00107a99-8b30-4a95-a694-efc8f57fa8ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "\n",
        "import numpy\n",
        "x1=numpy.linspace(1,len(historyT91.psnrs),len(historyT91.psnrs))\n",
        "y1 = numpy.asarray(historyT91.psnrs, dtype=numpy.float32)\n",
        "x2=numpy.linspace(1,len(historyBSDS200.psnrs),len(historyBSDS200.psnrs))\n",
        "y2 = numpy.asarray(historyBSDS200.psnrs, dtype=numpy.float32)\n",
        "x3=numpy.linspace(1,len(historyG100.psnrs),len(historyG100.psnrs))\n",
        "y3 = numpy.asarray(historyG100.psnrs, dtype=numpy.float32)\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(x1,y1, '-b', label='T91')\n",
        "ax.plot(x2,y2, '-r', label='BSDS200')\n",
        "ax.plot(x3,y3,'-g',label=\"G100\")\n",
        "\n",
        "\n",
        "leg = ax.legend();\n",
        "\n",
        "plt.show(fig)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD7CAYAAABzGc+QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58XNJ9mMDjF8",
        "colab_type": "code",
        "outputId": "438d6635-3a37-4cb1-f338-2813f0f46474",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "predict(\"935\",\"louvre.png\",\"T91\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(None, Non..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(3, 3), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(321, 481, 3) (321, 481)\n",
            "(1, 309, 469, 1)\n",
            "(321, 481, 3)\n",
            "(309, 469, 3) (309, 469, 3)\n",
            "bicubic:\n",
            "YCrCCb= 31.43739975246639 , RGB=31.440247781589335\n",
            "SRCNN:\n",
            "YCrCCb= 31.649815512138563 , RGB=31.65189434428698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXmcq3LSH5Oo",
        "colab_type": "code",
        "outputId": "d7bbdd25-a728-496e-c4bc-2b672c489b8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "predict(\"935\",\"louvre.png\",\"G100\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(None, Non..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(3, 3), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(321, 481, 3) (321, 481)\n",
            "(1, 309, 469, 1)\n",
            "(321, 481, 3)\n",
            "(309, 469, 3) (309, 469, 3)\n",
            "bicubic:\n",
            "YCrCCb= 31.43739975246639 , RGB=31.440247781589335\n",
            "SRCNN:\n",
            "YCrCCb= 31.74652800362521 , RGB=31.749714464830774\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi8onmLIH5X0",
        "colab_type": "code",
        "outputId": "005c9689-3f86-4745-c575-a95618ffbc1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "predict(\"935\",\"louvre.png\",\"BSDS200\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(None, Non..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(3, 3), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(321, 481, 3) (321, 481)\n",
            "(1, 309, 469, 1)\n",
            "(321, 481, 3)\n",
            "(309, 469, 3) (309, 469, 3)\n",
            "bicubic:\n",
            "YCrCCb= 31.43739975246639 , RGB=31.440247781589335\n",
            "SRCNN:\n",
            "YCrCCb= 31.92909934264071 , RGB=31.931081672565938\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}