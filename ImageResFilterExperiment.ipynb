{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageResFilterExperiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prateek1337/Image_Super_resolution/blob/master/ImageResFilterExperiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTLHSmW23asG",
        "colab_type": "code",
        "outputId": "05458a4e-e2d3-4b37-f743-1f674d1e614c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV7UDX6B3q7P",
        "colab_type": "code",
        "outputId": "4cd3dbd9-a946-4fc0-974c-527738bf3cf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import os \n",
        "os.chdir(\"/content/drive/My Drive/Image_Resolution/\")\n",
        "os.getcwd()\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " butterfly.png\t\t'Output of 915.png'\t SRCNN_check935.h5\n",
            " crop_train.h5\t\t'Output of 935.png'\t SRCNNCheck935.h5\n",
            " crop_trainTest.h5\t'Output of 955.png'\t SRCNN_check955.h5\n",
            " face.png\t\t'Output of the915.png'\t SRCNNCheck955.h5\n",
            " input2_rgb.png\t\t'Output of the935.png'\t SRCNN_check_rgb_9-3-5.h5\n",
            " input3_rgb.png\t\t'Output of the955.png'\t SRCNN_check_rgb_9-5-5.h5\n",
            " inputTes_rgb.png\t outTes_rgb.png\t\t SRCNN_check_rgb.h5\n",
            "'Input to 915.png'\t ppExp.jpg\t\t testFinal.h5\n",
            "'Input to 935.png'\t pp.jpg\t\t\t test.h5\n",
            "'Input to 955.png'\t prepare_data.py\t test_rgb.h5\n",
            "'Input to the 915.png'\t pre_rgb.png\t\t testTest.h5\n",
            "'Input to the 935.png'\t __pycache__\t\t trainFinal.h5\n",
            "'Input to the 955.png'\t SRCNN_check915.h5\t train_rgb.h5\n",
            " out22_rgb.png\t\t SRCNNCheck915.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk6-ZqmZ4bTg",
        "colab_type": "code",
        "outputId": "25e6ec26-27b8-4f4c-8f99-ce0574b25e64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "from keras import initializers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Input, BatchNormalization\n",
        "# from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.callbacks import ModelCheckpoint,Callback\n",
        "from keras.optimizers import SGD, Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import prepare_data as pd\n",
        "import numpy \n",
        "import math\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ninR1LjWtT29",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#setting seed for uniform results\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG0RN41fY1pk",
        "colab_type": "code",
        "outputId": "f9af813c-8a69-4cc2-8233-75bbef2ee8bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "data_Y, label_Y = pd.read_training_data(\"./testFinal.h5\")\n",
        "print(data_Y.shape,label_Y.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(420, 32, 32, 1) (420, 20, 20, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g-jFwan61pN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#9-1-5 Architecture \n",
        "def model915():\n",
        "    # lrelu = LeakyReLU(alpha=0.1)\n",
        "    SRCNN = Sequential()\n",
        "    SRCNN.add(Conv2D(nb_filter=128, nb_row=9, nb_col=9, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='valid', bias=True, input_shape=(32, 32, 1)))\n",
        "    SRCNN.add(Conv2D(nb_filter=64, nb_row=1, nb_col=1, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='same', bias=True))\n",
        "    # SRCNN.add(BatchNormalization())\n",
        "    SRCNN.add(Conv2D(nb_filter=1, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='linear', border_mode='valid', bias=True))\n",
        "    adam = Adam(lr=0.0003)\n",
        "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return SRCNN\n",
        "def predict_model915():\n",
        "    # lrelu = LeakyReLU(alpha=0.1)\n",
        "    SRCNN = Sequential()\n",
        "    SRCNN.add(Conv2D(nb_filter=128, nb_row=9, nb_col=9, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='valid', bias=True, input_shape=(None, None, 1)))\n",
        "    SRCNN.add(Conv2D(nb_filter=64, nb_row=1, nb_col=1, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='same', bias=True))\n",
        "    # SRCNN.add(BatchNormalization())\n",
        "    SRCNN.add(Conv2D(nb_filter=1, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='linear', border_mode='valid', bias=True))\n",
        "    adam = Adam(lr=0.0003)\n",
        "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return SRCNN\n",
        "\n",
        " \n",
        " \n",
        "#9-3-5 Architecture \n",
        "def model935():\n",
        "    # lrelu = LeakyReLU(alpha=0.1)\n",
        "    SRCNN = Sequential()\n",
        "    SRCNN.add(Conv2D(nb_filter=128, nb_row=9, nb_col=9, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='valid', bias=True, input_shape=(32, 32, 1)))\n",
        "    SRCNN.add(Conv2D(nb_filter=64, nb_row=3, nb_col=3, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='same', bias=True))\n",
        "    # SRCNN.add(BatchNormalization())\n",
        "    SRCNN.add(Conv2D(nb_filter=1, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='linear', border_mode='valid', bias=True))\n",
        "    adam = Adam(lr=0.0003)\n",
        "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return SRCNN\n",
        "def predict_model935():\n",
        "    # lrelu = LeakyReLU(alpha=0.1)\n",
        "    SRCNN = Sequential()\n",
        "    SRCNN.add(Conv2D(nb_filter=128, nb_row=9, nb_col=9, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='valid', bias=True, input_shape=(None, None, 1)))\n",
        "    SRCNN.add(Conv2D(nb_filter=64, nb_row=3, nb_col=3, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='same', bias=True))\n",
        "    # SRCNN.add(BatchNormalization())\n",
        "    SRCNN.add(Conv2D(nb_filter=1, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='linear', border_mode='valid', bias=True))\n",
        "    adam = Adam(lr=0.0003)\n",
        "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return SRCNN\n",
        "\n",
        "\n",
        " \n",
        "#9-5-5 Architecture \n",
        "def model955():\n",
        "    # lrelu = LeakyReLU(alpha=0.1)\n",
        "    SRCNN = Sequential()\n",
        "    SRCNN.add(Conv2D(nb_filter=128, nb_row=9, nb_col=9, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='valid', bias=True, input_shape=(32, 32, 1)))\n",
        "    SRCNN.add(Conv2D(nb_filter=64, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='same', bias=True))\n",
        "    # SRCNN.add(BatchNormalization())\n",
        "    SRCNN.add(Conv2D(nb_filter=1, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='linear', border_mode='valid', bias=True))\n",
        "    adam = Adam(lr=0.0003)\n",
        "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return SRCNN\n",
        "def predict_model955():\n",
        "    # lrelu = LeakyReLU(alpha=0.1)\n",
        "    SRCNN = Sequential()\n",
        "    SRCNN.add(Conv2D(nb_filter=128, nb_row=9, nb_col=9, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='valid', bias=True, input_shape=(None, None, 1)))\n",
        "    SRCNN.add(Conv2D(nb_filter=64, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='same', bias=True))\n",
        "    # SRCNN.add(BatchNormalization())\n",
        "    SRCNN.add(Conv2D(nb_filter=1, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='linear', border_mode='valid', bias=True))\n",
        "    adam = Adam(lr=0.0003)\n",
        "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return SRCNN\n",
        "\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOy6MsaDj1KS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def psnr(target, ref):\n",
        "    mse = numpy.mean( (target - ref) ** 2 )\n",
        "    PIXEL_MAX = 255.0\n",
        "    if mse == 0:\n",
        "        return 100\n",
        "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
        "\n",
        "\n",
        "\n",
        "class PsnrHistory(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.psnrs = []\n",
        "        \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        global modelArc\n",
        "        if modelArc==\"955\":\n",
        "          srcnn_model=predict_model955()\n",
        "          weights_file=\"SRCNN_check955.h5\"\n",
        "        elif modelArc==\"935\":\n",
        "          srcnn_model=predict_model935()\n",
        "          weights_file=\"SRCNN_check935.h5\"\n",
        "        elif modelArc==\"915\":\n",
        "          srcnn_model=predict_model915()\n",
        "          weights_file=\"SRCNN_check915.h5\"\n",
        "        srcnn_model.load_weights(weights_file)\n",
        "        avg_psnr=0.0\n",
        "        import cv2\n",
        "        for i in range(0,data_Y.shape[0]):\n",
        "            img=data_Y[i]\n",
        "            Y = numpy.zeros((1, img.shape[0], img.shape[1], 1), dtype=float)\n",
        "            Y[0, :, :, :] = img\n",
        "            pre = srcnn_model.predict(Y, batch_size=1) * 255.\n",
        "            pre[pre[:] > 255] = 255\n",
        "            pre[pre[:] < 0] = 0\n",
        "            img_pre=pre[0,:,:,:]\n",
        "            avg_psnr=avg_psnr+psnr(label_Y[i]*255, img_pre)\n",
        "\n",
        "        avg_psnr=(avg_psnr/data_Y.shape[0])\n",
        "        \n",
        "        self.psnrs.append((avg_psnr))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhRytvFCm-Eq",
        "colab_type": "code",
        "outputId": "c3b5982b-bce4-43d1-9e50-0dec77a854ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#TPU EXPERIMENTATION TRY LATER\n",
        "try:\n",
        "  device_name = os.environ['COLAB_TPU_ADDR']\n",
        "  TPU_ADDRESS = 'grpc://' + device_name\n",
        "  print('Found TPU at: {}'.format(TPU_ADDRESS))\n",
        "\n",
        "except KeyError:\n",
        "  print('TPU not found')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy9tcl-clzp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TPU EXPERIMENTATION TRY LATER\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "tpu_model915 = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model915,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(\n",
        "            tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "    )\n",
        ")\n",
        "tpu_model935 = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model935,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(\n",
        "            tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "    )\n",
        ")\n",
        "tpu_model955 = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model955,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(\n",
        "            tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "    )\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBbPfb1Zj2ha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(history,arch):\n",
        "    \n",
        "    if arch==\"915\":\n",
        "      srcnn_model = model915()\n",
        "    elif arch==\"935\":\n",
        "      srcnn_model=model935()\n",
        "      \n",
        "    else:\n",
        "      srcnn_model=model955()\n",
        "      \n",
        "    print(srcnn_model.summary())\n",
        "    data, label = pd.read_training_data(\"./trainFinal.h5\")\n",
        "    val_data, val_label = pd.read_training_data(\"./testFinal.h5\")\n",
        "    global modelArc\n",
        "    modelArc=arch\n",
        "    h5File=\"SRCNN_check\"+arch+\".h5\"\n",
        "    checkpoint = ModelCheckpoint(h5File, monitor='val_loss', verbose=1, save_best_only=True,\n",
        "                                 save_weights_only=False, mode='min')\n",
        "    callbacks_list = [checkpoint,history]\n",
        "\n",
        "    srcnn_model.fit(data, label, batch_size=128, validation_data=(val_data, val_label),\n",
        "                    callbacks=callbacks_list, shuffle=True, nb_epoch=200, verbose=0)\n",
        "    # srcnn_model.load_weights(\"m_model_adam.h5\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0EjckXcwdTG",
        "colab_type": "code",
        "outputId": "1cbb9382-c3d3-476a-f132-0975859c2496",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history915=PsnrHistory()\n",
        "\n",
        "\n",
        "train(history915,\"915\")\n",
        "print(\"Final Psnr:\",history915.psnrs[-1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 128)       10496     \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        8256      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 20, 20, 1)         1601      \n",
            "=================================================================\n",
            "Total params: 20,353\n",
            "Trainable params: 20,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(32, 32, 1..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(1, 1), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.00297, saving model to SRCNN_check915.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(None, Non..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(1, 1), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00002: val_loss improved from 0.00297 to 0.00210, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.00210 to 0.00183, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.00183 to 0.00169, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00169 to 0.00161, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00161 to 0.00158, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00158 to 0.00154, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00154 to 0.00152, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00152 to 0.00150, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00150 to 0.00148, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00148 to 0.00147, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00147 to 0.00146, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00146 to 0.00145, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00145 to 0.00144, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00144 to 0.00143, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00143 to 0.00143, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00143 to 0.00142, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00142 to 0.00142, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00142 to 0.00141, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00141\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.00141 to 0.00141, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00141 to 0.00141, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00141 to 0.00141, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00141 to 0.00141, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.00141 to 0.00140, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00140\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.00140 to 0.00140, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00140\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.00140 to 0.00139, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00139\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00139\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00139\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.00139 to 0.00138, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00138\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.00138 to 0.00138, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.00138\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.00138 to 0.00137, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00137\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.00137 to 0.00137, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.00137\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.00137\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.00137 to 0.00136, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.00136\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.00136\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00136\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00136\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00136\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00136\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00136\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.00136 to 0.00135, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00057: val_loss improved from 0.00135 to 0.00135, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00058: val_loss improved from 0.00135 to 0.00134, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.00134\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.00134\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.00134\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.00134 to 0.00133, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.00133\n",
            "\n",
            "Epoch 00064: val_loss improved from 0.00133 to 0.00133, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00065: val_loss improved from 0.00133 to 0.00131, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00070: val_loss improved from 0.00131 to 0.00131, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00089: val_loss improved from 0.00131 to 0.00131, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00094: val_loss improved from 0.00131 to 0.00130, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00096: val_loss improved from 0.00130 to 0.00130, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00106: val_loss improved from 0.00130 to 0.00129, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00115: val_loss improved from 0.00129 to 0.00129, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00126: val_loss improved from 0.00129 to 0.00129, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00127: val_loss improved from 0.00129 to 0.00129, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00139: val_loss improved from 0.00129 to 0.00128, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00150: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00157: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00159: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00165: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00170: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00176: val_loss improved from 0.00128 to 0.00127, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.00127\n",
            "Final Psnr: 33.79586964075874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAJr8VdLaqjC",
        "colab_type": "code",
        "outputId": "74404c86-47c8-4b02-e8b2-0ab60eeeb731",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history935=PsnrHistory()\n",
        "\n",
        "\n",
        "train(history935,\"935\")\n",
        "print(\"Final Psnr:\",history935.psnrs[-1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_202\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_604 (Conv2D)          (None, 24, 24, 128)       10496     \n",
            "_________________________________________________________________\n",
            "conv2d_605 (Conv2D)          (None, 24, 24, 64)        73792     \n",
            "_________________________________________________________________\n",
            "conv2d_606 (Conv2D)          (None, 20, 20, 1)         1601      \n",
            "=================================================================\n",
            "Total params: 85,889\n",
            "Trainable params: 85,889\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(32, 32, 1..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(3, 3), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.00276, saving model to SRCNN_check935.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(None, Non..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(3, 3), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00002: val_loss improved from 0.00276 to 0.00175, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.00175 to 0.00157, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.00157 to 0.00151, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00151 to 0.00147, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00147 to 0.00146, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.00146\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00146 to 0.00143, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00143 to 0.00143, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00143 to 0.00142, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00142 to 0.00142, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00142 to 0.00140, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.00140\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00140 to 0.00140, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00140 to 0.00139, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00139 to 0.00138, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00138 to 0.00138, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00138\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00138 to 0.00137, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00137\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00137\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00137 to 0.00136, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.00136\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00136 to 0.00135, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.00135 to 0.00135, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.00135 to 0.00135, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.00135 to 0.00135, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.00135 to 0.00134, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.00134 to 0.00134, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.00134 to 0.00133, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.00133\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.00133\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00133\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.00133 to 0.00132, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.00132 to 0.00132, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.00132 to 0.00131, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00052: val_loss improved from 0.00131 to 0.00131, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00061: val_loss improved from 0.00131 to 0.00130, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00067: val_loss improved from 0.00130 to 0.00129, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00072: val_loss improved from 0.00129 to 0.00129, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00074: val_loss improved from 0.00129 to 0.00129, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00076: val_loss improved from 0.00129 to 0.00129, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00078: val_loss improved from 0.00129 to 0.00128, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00093: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00096: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00107: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.00128\n",
            "Final Psnr: 33.499461381068166\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSiTc-iparFv",
        "colab_type": "code",
        "outputId": "a947ae20-37b8-4f2d-d00e-ee0b718c2cf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history955=PsnrHistory()\n",
        "\n",
        "\n",
        "train(history955,\"955\")\n",
        "print(\"Final Psnr:\",history955.psnrs)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_403\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1207 (Conv2D)         (None, 24, 24, 128)       10496     \n",
            "_________________________________________________________________\n",
            "conv2d_1208 (Conv2D)         (None, 24, 24, 64)        204864    \n",
            "_________________________________________________________________\n",
            "conv2d_1209 (Conv2D)         (None, 20, 20, 1)         1601      \n",
            "=================================================================\n",
            "Total params: 216,961\n",
            "Trainable params: 216,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(32, 32, 1..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:67: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(5, 5), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.00196, saving model to SRCNN_check955.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:78: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(None, Non..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:80: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(5, 5), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:83: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00002: val_loss improved from 0.00196 to 0.00159, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.00159 to 0.00151, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.00151 to 0.00147, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00147 to 0.00144, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00144 to 0.00144, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00144 to 0.00142, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00142 to 0.00142, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00142 to 0.00140, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.00140\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00140 to 0.00140, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.00140\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.00140\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00140 to 0.00138, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00138 to 0.00138, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00138 to 0.00137, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00137 to 0.00137, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00137\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00137 to 0.00136, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00136\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00136\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00136 to 0.00135, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.00135 to 0.00134, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.00134 to 0.00134, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00134\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.00134 to 0.00132, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.00132 to 0.00132, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.00132 to 0.00131, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.00131 to 0.00130, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.00130 to 0.00130, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00053: val_loss improved from 0.00130 to 0.00129, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00055: val_loss improved from 0.00129 to 0.00129, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.00129 to 0.00128, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00076: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00099: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00100: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.00128\n",
            "Final Psnr: [31.429175376503427, 32.33863570784442, 32.74774712388154, 32.741924607124176, 32.97998730809916, 33.00833484499052, 32.85893469798903, 32.981592223147686, 33.06543942498493, 33.06543942498493, 32.69464798437773, 32.69464798437773, 32.69464798437773, 33.22442464600187, 33.01225600994368, 33.11444195495178, 33.21739570746936, 33.21739570746936, 33.129180859885274, 33.129180859885274, 33.129180859885274, 33.03232673097626, 33.03232673097626, 33.03232673097626, 33.03232673097626, 33.03232673097626, 33.03232673097626, 33.19649060407735, 33.184584472411004, 33.184584472411004, 33.16607019311925, 33.31148329208013, 33.31148329208013, 33.31148329208013, 33.35473527903979, 33.35473527903979, 33.35473527903979, 33.35473527903979, 33.35473527903979, 33.19727587539622, 33.19727587539622, 33.19727587539622, 33.19727587539622, 33.19727587539622, 33.27654038798981, 33.27654038798981, 33.27654038798981, 33.27654038798981, 33.27654038798981, 33.27654038798981, 33.27654038798981, 33.27654038798981, 33.38281666071796, 33.38281666071796, 33.38152037271323, 33.38152037271323, 33.38152037271323, 33.38152037271323, 33.38152037271323, 33.38152037271323, 33.38152037271323, 33.41584776536911, 33.41584776536911, 33.41584776536911, 33.41584776536911, 33.41584776536911, 33.41584776536911, 33.41584776536911, 33.41584776536911, 33.41584776536911, 33.41584776536911, 33.41584776536911, 33.41584776536911, 33.41584776536911, 33.41584776536911, 33.46664644153496, 33.46664644153496, 33.46664644153496, 33.46664644153496, 33.46664644153496, 33.46664644153496, 33.46664644153496, 33.46664644153496, 33.46664644153496, 33.46664644153496, 33.46664644153496, 33.46664644153496, 33.46664644153496, 33.46664644153496, 33.46664644153496, 33.46664644153496, 33.46664644153496, 33.46664644153496, 33.46664644153496, 33.46664644153496, 33.46664644153496, 33.46664644153496, 33.46664644153496, 33.502812728165615, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549, 33.54830978061549]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU4Y1ywhlAot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(architecture,file_name):\n",
        "    if architecture==\"915\":\n",
        "      srcnn_model = predict_model915()\n",
        "    elif architecture==\"935\":\n",
        "      srcnn_model=predict_model935()\n",
        "    else:\n",
        "      srcnn_model=predict_model955()\n",
        "    weight_file=\"SRCNN_check\"+architecture+\".h5\" \n",
        "    srcnn_model.load_weights(weight_file)\n",
        "    IMG_NAME = file_name\n",
        "    INPUT_NAME = \"Input to the \"+architecture+\".png\"\n",
        "    OUTPUT_NAME = \"Output of the\"+architecture+\".png\"\n",
        "\n",
        "    import cv2\n",
        "    img = cv2.imread(IMG_NAME, cv2.IMREAD_COLOR)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
        "    shape = img.shape\n",
        "    Y_img = cv2.resize(img[:, :, 0], (int(shape[1] / 2), int(shape[0] / 2)), cv2.INTER_CUBIC)\n",
        "    Y_img = cv2.resize(Y_img, (shape[1], shape[0]), cv2.INTER_CUBIC)\n",
        "    print(img.shape,Y_img.shape)\n",
        "    img[:, :, 0] = Y_img\n",
        "    Y_img=img[:,:,0]\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_YCrCb2BGR)\n",
        "    cv2.imwrite(INPUT_NAME, img)\n",
        "\n",
        "    Y = numpy.zeros((1, img.shape[0], img.shape[1], 1), dtype=float)\n",
        "    Y[0, :, :, 0] = Y_img.astype(float) / 255.\n",
        "    pre = srcnn_model.predict(Y, batch_size=1) * 255.\n",
        "    print(pre.shape)\n",
        "    pre[pre[:] > 255] = 255\n",
        "    pre[pre[:] < 0] = 0\n",
        "    pre = pre.astype(numpy.uint8)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
        "    img[6: -6, 6: -6, 0] = pre[0, :, :, 0]\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_YCrCb2BGR)\n",
        "    print(img.shape)\n",
        "    cv2.imwrite(OUTPUT_NAME, img)\n",
        "\n",
        "    # psnr calculation:\n",
        "    im1_rgb = cv2.imread(IMG_NAME, cv2.IMREAD_COLOR)[6: -6, 6: -6, :]\n",
        "    im1_Y = cv2.cvtColor(im1_rgb, cv2.COLOR_BGR2YCrCb)\n",
        "    im2_rgb = cv2.imread(INPUT_NAME, cv2.IMREAD_COLOR)[6: -6, 6: -6, :]\n",
        "    im2_Y = cv2.cvtColor(im2_rgb, cv2.COLOR_BGR2YCrCb)\n",
        "    im3_rgb = cv2.imread(OUTPUT_NAME, cv2.IMREAD_COLOR)[6: -6, 6: -6, :]\n",
        "    im3_Y = cv2.cvtColor(im3_rgb, cv2.COLOR_BGR2YCrCb)\n",
        "    print(im3_Y.shape,im1_Y.shape)\n",
        "    print(\"bicubic:\")\n",
        "    print(\"YCrCCb= {} , RGB={}\".format(psnr(im1_Y[:,:,0],im2_Y[:,:,0]),psnr(im1_rgb,im2_rgb)))\n",
        "    print(\"SRCNN:\")\n",
        "    print(\"YCrCCb= {} , RGB={}\".format(psnr(im1_Y[:,:,0],im3_Y[:,:,0]),psnr(im1_rgb,im3_rgb)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87FeW85u8L7c",
        "colab_type": "code",
        "outputId": "4dcdd425-1b50-408b-b219-848c4a9aafec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "\n",
        "import numpy\n",
        "x1=numpy.linspace(1,len(history915.psnrs),len(history915.psnrs))\n",
        "y1 = numpy.asarray(history915.psnrs, dtype=numpy.float32)\n",
        "x2=numpy.linspace(1,len(history935.psnrs),len(history935.psnrs))\n",
        "y2 = numpy.asarray(history935.psnrs, dtype=numpy.float32)\n",
        "x3=numpy.linspace(1,len(history955.psnrs),len(history955.psnrs))\n",
        "y3 = numpy.asarray(history955.psnrs, dtype=numpy.float32)\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(x1,y1, '-b', label='9-1-5')\n",
        "ax.plot(x2,y2, '-r', label='9-3-5')\n",
        "ax.plot(x3,y3,'-g',label='9-5-5')\n",
        "\n",
        "leg = ax.legend();\n",
        "\n",
        "plt.show(fig)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD6CAYAAACvZ4z8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nV0opl9NEr5RSLqeJXimlXO7/A74ciOFUVJEKAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58XNJ9mMDjF8",
        "colab_type": "code",
        "outputId": "12e90d42-c04a-4d03-91ea-392af7b7f4de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "predict(\"915\",\"face.png\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(None, Non..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(1, 1), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(276, 276, 3) (276, 276)\n",
            "(1, 264, 264, 1)\n",
            "(276, 276, 3)\n",
            "(264, 264, 3) (264, 264, 3)\n",
            "bicubic:\n",
            "YCrCCb= 33.58214074570319 , RGB=33.57164752219919\n",
            "SRCNN:\n",
            "YCrCCb= 34.25156965313028 , RGB=34.21562691773806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXmcq3LSH5Oo",
        "colab_type": "code",
        "outputId": "c6ae1cd8-c351-4c7d-94f6-19d77d16e3df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "predict(\"935\",\"face.png\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(None, Non..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(3, 3), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(276, 276, 3) (276, 276)\n",
            "(1, 264, 264, 1)\n",
            "(276, 276, 3)\n",
            "(264, 264, 3) (264, 264, 3)\n",
            "bicubic:\n",
            "YCrCCb= 33.58214074570319 , RGB=33.57164752219919\n",
            "SRCNN:\n",
            "YCrCCb= 34.25657438561433 , RGB=34.21636394884406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi8onmLIH5X0",
        "colab_type": "code",
        "outputId": "c4638dbc-061e-405e-8def-7c5fc19d6f86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "predict(\"955\",\"face.png\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:78: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(None, Non..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:80: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(5, 5), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:83: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(276, 276, 3) (276, 276)\n",
            "(1, 264, 264, 1)\n",
            "(276, 276, 3)\n",
            "(264, 264, 3) (264, 264, 3)\n",
            "bicubic:\n",
            "YCrCCb= 33.58214074570319 , RGB=33.57164752219919\n",
            "SRCNN:\n",
            "YCrCCb= 34.2758893216443 , RGB=34.23496092739847\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}