{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageResFilterExperiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prateek1337/Image_Super_resolution/blob/master/ImageResFilterExperiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTLHSmW23asG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "outputId": "e1986c5d-61da-4eaf-b071-64d6697e6cc8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV7UDX6B3q7P",
        "colab_type": "code",
        "outputId": "add16b9b-4a0a-4f45-c812-c7bc9d9bf52f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "source": [
        "import os \n",
        "os.chdir(\"/content/drive/My Drive/Image_Resolution/\")\n",
        "os.getcwd()\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " butterfly.png\t\t out22_rgb.png\t\t SRCNNCheck915.h5\n",
            " crop_train.h5\t\t'Output of 915.png'\t SRCNN_check935.h5\n",
            " face.png\t\t'Output of 935.png'\t SRCNNCheck935.h5\n",
            " input2_rgb.png\t\t'Output of 955.png'\t SRCNN_check955.h5\n",
            " input3_rgb.png\t\t'Output of the915.png'\t SRCNNCheck955.h5\n",
            " inputTes_rgb.png\t'Output of the935.png'\t SRCNN_check_rgb_9-3-5.h5\n",
            "'Input to 915.png'\t'Output of the955.png'\t SRCNN_check_rgb_9-5-5.h5\n",
            "'Input to 935.png'\t outTes_rgb.png\t\t SRCNN_check_rgb.h5\n",
            "'Input to 955.png'\t prepare_data.py\t test.h5\n",
            "'Input to the 915.png'\t pre_rgb.png\t\t test_rgb.h5\n",
            "'Input to the 935.png'\t __pycache__\t\t train_rgb.h5\n",
            "'Input to the 955.png'\t SRCNN_check915.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk6-ZqmZ4bTg",
        "colab_type": "code",
        "outputId": "d22d1aed-a38a-4196-ff12-ac875767bdd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from keras import initializers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Input, BatchNormalization\n",
        "# from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.callbacks import ModelCheckpoint,Callback\n",
        "from keras.optimizers import SGD, Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import prepare_data as pd\n",
        "import numpy \n",
        "import math\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ninR1LjWtT29",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#setting seed for uniform results\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG0RN41fY1pk",
        "colab_type": "code",
        "outputId": "578c556b-9c94-4dab-e048-bb5647388341",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "data_Y, label_Y = pd.read_training_data(\"./test.h5\")\n",
        "print(data_Y.shape,label_Y.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(420, 32, 32, 1) (420, 20, 20, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g-jFwan61pN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#9-1-5 Architecture \n",
        "def model915():\n",
        "    # lrelu = LeakyReLU(alpha=0.1)\n",
        "    SRCNN = Sequential()\n",
        "    SRCNN.add(Conv2D(nb_filter=128, nb_row=9, nb_col=9, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='valid', bias=True, input_shape=(32, 32, 1)))\n",
        "    SRCNN.add(Conv2D(nb_filter=64, nb_row=1, nb_col=1, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='same', bias=True))\n",
        "    # SRCNN.add(BatchNormalization())\n",
        "    SRCNN.add(Conv2D(nb_filter=1, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='linear', border_mode='valid', bias=True))\n",
        "    adam = Adam(lr=0.0003)\n",
        "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return SRCNN\n",
        "def predict_model915():\n",
        "    # lrelu = LeakyReLU(alpha=0.1)\n",
        "    SRCNN = Sequential()\n",
        "    SRCNN.add(Conv2D(nb_filter=128, nb_row=9, nb_col=9, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='valid', bias=True, input_shape=(None, None, 1)))\n",
        "    SRCNN.add(Conv2D(nb_filter=64, nb_row=1, nb_col=1, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='same', bias=True))\n",
        "    # SRCNN.add(BatchNormalization())\n",
        "    SRCNN.add(Conv2D(nb_filter=1, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='linear', border_mode='valid', bias=True))\n",
        "    adam = Adam(lr=0.0003)\n",
        "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return SRCNN\n",
        "\n",
        " \n",
        " \n",
        "#9-3-5 Architecture \n",
        "def model935():\n",
        "    # lrelu = LeakyReLU(alpha=0.1)\n",
        "    SRCNN = Sequential()\n",
        "    SRCNN.add(Conv2D(nb_filter=128, nb_row=9, nb_col=9, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='valid', bias=True, input_shape=(32, 32, 1)))\n",
        "    SRCNN.add(Conv2D(nb_filter=64, nb_row=3, nb_col=3, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='same', bias=True))\n",
        "    # SRCNN.add(BatchNormalization())\n",
        "    SRCNN.add(Conv2D(nb_filter=1, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='linear', border_mode='valid', bias=True))\n",
        "    adam = Adam(lr=0.0003)\n",
        "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return SRCNN\n",
        "def predict_model935():\n",
        "    # lrelu = LeakyReLU(alpha=0.1)\n",
        "    SRCNN = Sequential()\n",
        "    SRCNN.add(Conv2D(nb_filter=128, nb_row=9, nb_col=9, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='valid', bias=True, input_shape=(None, None, 1)))\n",
        "    SRCNN.add(Conv2D(nb_filter=64, nb_row=3, nb_col=3, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='same', bias=True))\n",
        "    # SRCNN.add(BatchNormalization())\n",
        "    SRCNN.add(Conv2D(nb_filter=1, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='linear', border_mode='valid', bias=True))\n",
        "    adam = Adam(lr=0.0003)\n",
        "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return SRCNN\n",
        "\n",
        "\n",
        " \n",
        "#9-5-5 Architecture \n",
        "def model955():\n",
        "    # lrelu = LeakyReLU(alpha=0.1)\n",
        "    SRCNN = Sequential()\n",
        "    SRCNN.add(Conv2D(nb_filter=128, nb_row=9, nb_col=9, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='valid', bias=True, input_shape=(32, 32, 1)))\n",
        "    SRCNN.add(Conv2D(nb_filter=64, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='same', bias=True))\n",
        "    # SRCNN.add(BatchNormalization())\n",
        "    SRCNN.add(Conv2D(nb_filter=1, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='linear', border_mode='valid', bias=True))\n",
        "    adam = Adam(lr=0.0003)\n",
        "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return SRCNN\n",
        "def predict_model955():\n",
        "    # lrelu = LeakyReLU(alpha=0.1)\n",
        "    SRCNN = Sequential()\n",
        "    SRCNN.add(Conv2D(nb_filter=128, nb_row=9, nb_col=9, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='valid', bias=True, input_shape=(None, None, 1)))\n",
        "    SRCNN.add(Conv2D(nb_filter=64, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='same', bias=True))\n",
        "    # SRCNN.add(BatchNormalization())\n",
        "    SRCNN.add(Conv2D(nb_filter=1, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='linear', border_mode='valid', bias=True))\n",
        "    adam = Adam(lr=0.0003)\n",
        "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return SRCNN\n",
        "\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOy6MsaDj1KS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def psnr(target, ref):\n",
        "    mse = numpy.mean( (target - ref) ** 2 )\n",
        "    PIXEL_MAX = 255.0\n",
        "    if mse == 0:\n",
        "        return 100\n",
        "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
        "\n",
        "\n",
        "\n",
        "class PsnrHistory(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.psnrs = []\n",
        "        \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        global modelArc\n",
        "        if modelArc==\"955\":\n",
        "          srcnn_model=predict_model955()\n",
        "          weights_file=\"SRCNN_check955.h5\"\n",
        "        elif modelArc==\"935\":\n",
        "          srcnn_model=predict_model935()\n",
        "          weights_file=\"SRCNN_check935.h5\"\n",
        "        elif modelArc==\"915\":\n",
        "          srcnn_model=predict_model915()\n",
        "          weights_file=\"SRCNN_check915.h5\"\n",
        "        srcnn_model.load_weights(weights_file)\n",
        "        avg_psnr=0.0\n",
        "        import cv2\n",
        "        for i in range(0,data_Y.shape[0]):\n",
        "            img=data_Y[i]\n",
        "            Y = numpy.zeros((1, img.shape[0], img.shape[1], 1), dtype=float)\n",
        "            Y[0, :, :, :] = img\n",
        "            pre = srcnn_model.predict(Y, batch_size=1) * 255.\n",
        "            pre[pre[:] > 255] = 255\n",
        "            pre[pre[:] < 0] = 0\n",
        "            img_pre=pre[0,:,:,:]\n",
        "            avg_psnr=avg_psnr+psnr(label_Y[i]*255, img_pre)\n",
        "\n",
        "        avg_psnr=(avg_psnr/data_Y.shape[0])\n",
        "        \n",
        "        self.psnrs.append((avg_psnr))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhRytvFCm-Eq",
        "colab_type": "code",
        "outputId": "c3b5982b-bce4-43d1-9e50-0dec77a854ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#TPU EXPERIMENTATION TRY LATER\n",
        "try:\n",
        "  device_name = os.environ['COLAB_TPU_ADDR']\n",
        "  TPU_ADDRESS = 'grpc://' + device_name\n",
        "  print('Found TPU at: {}'.format(TPU_ADDRESS))\n",
        "\n",
        "except KeyError:\n",
        "  print('TPU not found')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy9tcl-clzp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TPU EXPERIMENTATION TRY LATER\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "tpu_model915 = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model915,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(\n",
        "            tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "    )\n",
        ")\n",
        "tpu_model935 = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model935,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(\n",
        "            tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "    )\n",
        ")\n",
        "tpu_model955 = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model955,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(\n",
        "            tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "    )\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBbPfb1Zj2ha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(history,arch):\n",
        "    \n",
        "    if arch==\"915\":\n",
        "      srcnn_model = model915()\n",
        "    elif arch==\"935\":\n",
        "      srcnn_model=model935()\n",
        "      \n",
        "    else:\n",
        "      srcnn_model=model955()\n",
        "      \n",
        "    print(srcnn_model.summary())\n",
        "    data, label = pd.read_training_data(\"./crop_train.h5\")\n",
        "    val_data, val_label = pd.read_training_data(\"./test.h5\")\n",
        "    global modelArc\n",
        "    modelArc=arch\n",
        "    h5File=\"SRCNN_check\"+arch+\".h5\"\n",
        "    checkpoint = ModelCheckpoint(h5File, monitor='val_loss', verbose=1, save_best_only=True,\n",
        "                                 save_weights_only=False, mode='min')\n",
        "    callbacks_list = [checkpoint,history]\n",
        "\n",
        "    srcnn_model.fit(data, label, batch_size=128, validation_data=(val_data, val_label),\n",
        "                    callbacks=callbacks_list, shuffle=True, nb_epoch=200, verbose=0)\n",
        "    # srcnn_model.load_weights(\"m_model_adam.h5\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0EjckXcwdTG",
        "colab_type": "code",
        "outputId": "0d235080-0713-4482-d5bf-edfc2f721b06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history915=PsnrHistory()\n",
        "\n",
        "\n",
        "train(history915,\"915\")\n",
        "print(history915.psnrs)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(32, 32, 1..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(1, 1), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_203\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_607 (Conv2D)          (None, 24, 24, 128)       10496     \n",
            "_________________________________________________________________\n",
            "conv2d_608 (Conv2D)          (None, 24, 24, 64)        8256      \n",
            "_________________________________________________________________\n",
            "conv2d_609 (Conv2D)          (None, 20, 20, 1)         1601      \n",
            "=================================================================\n",
            "Total params: 20,353\n",
            "Trainable params: 20,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.00695, saving model to SRCNN_check915.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(None, Non..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(1, 1), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00002: val_loss improved from 0.00695 to 0.00494, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.00494 to 0.00362, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.00362 to 0.00287, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00287 to 0.00249, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00249 to 0.00216, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00216 to 0.00196, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00196 to 0.00185, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00185 to 0.00177, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00177 to 0.00170, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00170 to 0.00164, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00164 to 0.00159, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00159 to 0.00156, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00156 to 0.00153, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00153 to 0.00153, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00153 to 0.00150, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00150 to 0.00147, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00147 to 0.00146, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.00146\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.00146 to 0.00145, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.00145 to 0.00144, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00144 to 0.00143, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00143 to 0.00142, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00142 to 0.00142, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.00142 to 0.00142, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.00142 to 0.00141, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.00141 to 0.00140, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00140\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.00140 to 0.00140, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00140\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.00140 to 0.00139, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.00139 to 0.00139, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.00139 to 0.00138, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.00138 to 0.00138, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.00138 to 0.00138, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.00138 to 0.00138, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.00138 to 0.00138, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00138\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.00138 to 0.00137, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.00137 to 0.00137, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.00137\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.00137 to 0.00136, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.00136 to 0.00136, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.00136 to 0.00136, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00136\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.00136 to 0.00136, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.00136 to 0.00136, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00136\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00136\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.00136 to 0.00135, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.00135 to 0.00135, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00055: val_loss improved from 0.00135 to 0.00135, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00057: val_loss improved from 0.00135 to 0.00134, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.00134\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.00134\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.00134\n",
            "\n",
            "Epoch 00061: val_loss improved from 0.00134 to 0.00134, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.00134 to 0.00133, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00063: val_loss improved from 0.00133 to 0.00133, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.00133\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.00133\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.00133\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.00133\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.00133\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.00133\n",
            "\n",
            "Epoch 00070: val_loss improved from 0.00133 to 0.00133, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00071: val_loss improved from 0.00133 to 0.00133, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.00133\n",
            "\n",
            "Epoch 00073: val_loss improved from 0.00133 to 0.00133, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00074: val_loss improved from 0.00133 to 0.00133, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.00133\n",
            "\n",
            "Epoch 00076: val_loss improved from 0.00133 to 0.00132, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00085: val_loss improved from 0.00132 to 0.00132, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00087: val_loss improved from 0.00132 to 0.00131, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00094: val_loss improved from 0.00131 to 0.00131, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00100: val_loss improved from 0.00131 to 0.00131, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00102: val_loss improved from 0.00131 to 0.00131, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00107: val_loss improved from 0.00131 to 0.00131, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00114: val_loss improved from 0.00131 to 0.00130, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00117: val_loss improved from 0.00130 to 0.00130, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00118: val_loss improved from 0.00130 to 0.00130, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00122: val_loss improved from 0.00130 to 0.00130, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00124: val_loss improved from 0.00130 to 0.00130, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00128: val_loss improved from 0.00130 to 0.00129, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00132: val_loss improved from 0.00129 to 0.00129, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00138: val_loss improved from 0.00129 to 0.00129, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00141: val_loss improved from 0.00129 to 0.00129, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00148: val_loss improved from 0.00129 to 0.00128, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00157: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00159: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00163: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00164: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00169: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00172: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00174: val_loss improved from 0.00128 to 0.00127, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00186: val_loss improved from 0.00127 to 0.00127, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00192: val_loss improved from 0.00127 to 0.00127, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.00127\n",
            "[24.257113550177678, 27.753285876462428, 28.94220396433572, 29.4252267375962, 30.728151520898507, 30.72619693378564, 30.884551925560316, 31.748899062874997, 32.20850333181732, 32.25209535135129, 32.38790673547544, 32.26312449898858, 32.45121290948144, 32.33895748109951, 31.883287217986812, 32.740138810044925, 32.983245283275494, 32.900285910774336, 32.900285910774336, 32.84709633530833, 32.65907912455705, 32.886053919077234, 32.807070516831885, 32.97061838972724, 32.89007206891593, 32.942044947759285, 33.0632353052082, 33.0632353052082, 33.20509423357086, 33.20509423357086, 32.64579427228832, 33.13675315363821, 32.946096724394145, 32.98464644260399, 33.108888878255165, 32.8069722262793, 33.11394462854959, 33.11394462854959, 32.914097966431896, 33.28661443509329, 33.28661443509329, 33.16810912488595, 32.83961890742189, 33.087840634085545, 33.087840634085545, 32.780029192307914, 32.91238316155217, 32.91238316155217, 32.91238316155217, 33.06503735820098, 33.06503735820098, 33.06503735820098, 33.06503735820098, 33.21442248071561, 33.2746509852778, 33.2746509852778, 33.10961651340536, 33.10961651340536, 33.10961651340536, 33.10961651340536, 32.81510922245161, 33.35212658940202, 33.276140977220656, 33.276140977220656, 33.276140977220656, 33.276140977220656, 33.276140977220656, 33.276140977220656, 33.276140977220656, 33.39779898853098, 32.951699059405485, 32.951699059405485, 33.224805866327614, 33.31594170905377, 33.31594170905377, 33.44149404191197, 33.44149404191197, 33.44149404191197, 33.44149404191197, 33.44149404191197, 33.44149404191197, 33.44149404191197, 33.44149404191197, 33.44149404191197, 33.303104987792665, 33.303104987792665, 33.44896657160876, 33.44896657160876, 33.44896657160876, 33.44896657160876, 33.44896657160876, 33.44896657160876, 33.44896657160876, 33.084537290875836, 33.084537290875836, 33.084537290875836, 33.084537290875836, 33.084537290875836, 33.084537290875836, 33.2880044579064, 33.2880044579064, 33.23748755917383, 33.23748755917383, 33.23748755917383, 33.23748755917383, 33.23748755917383, 33.21058143858006, 33.21058143858006, 33.21058143858006, 33.21058143858006, 33.21058143858006, 33.21058143858006, 33.21058143858006, 33.026433533065926, 33.026433533065926, 33.026433533065926, 33.50073380065238, 33.13252574534363, 33.13252574534363, 33.13252574534363, 33.13252574534363, 33.54772910011508, 33.54772910011508, 33.01006770205918, 33.01006770205918, 33.01006770205918, 33.01006770205918, 33.40712802647251, 33.40712802647251, 33.40712802647251, 33.40712802647251, 33.45364634695011, 33.45364634695011, 33.45364634695011, 33.45364634695011, 33.45364634695011, 33.45364634695011, 33.45161333723609, 33.45161333723609, 33.45161333723609, 33.26859001147292, 33.26859001147292, 33.26859001147292, 33.26859001147292, 33.26859001147292, 33.26859001147292, 33.26859001147292, 33.216299534951155, 33.216299534951155, 33.216299534951155, 33.216299534951155, 33.216299534951155, 33.216299534951155, 33.216299534951155, 33.216299534951155, 33.216299534951155, 33.5014209209397, 33.5014209209397, 33.5749770744577, 33.5749770744577, 33.5749770744577, 33.5749770744577, 33.46917401442076, 33.55499180187366, 33.55499180187366, 33.55499180187366, 33.55499180187366, 33.55499180187366, 33.211608402887556, 33.211608402887556, 33.211608402887556, 33.63436517400327, 33.63436517400327, 33.53771780502155, 33.53771780502155, 33.53771780502155, 33.53771780502155, 33.53771780502155, 33.53771780502155, 33.53771780502155, 33.53771780502155, 33.53771780502155, 33.53771780502155, 33.53771780502155, 33.53771780502155, 33.64593156631169, 33.64593156631169, 33.64593156631169, 33.64593156631169, 33.64593156631169, 33.64593156631169, 33.30824434988034, 33.30824434988034, 33.30824434988034, 33.30824434988034, 33.30824434988034, 33.30824434988034, 33.30824434988034, 33.30824434988034, 33.30824434988034]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAJr8VdLaqjC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "025d8bfa-570c-4d9b-eb47-686291b57143"
      },
      "source": [
        "history935=PsnrHistory()\n",
        "\n",
        "\n",
        "train(history935,\"935\")\n",
        "print(history935.psnrs)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(32, 32, 1..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(3, 3), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_404\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1210 (Conv2D)         (None, 24, 24, 128)       10496     \n",
            "_________________________________________________________________\n",
            "conv2d_1211 (Conv2D)         (None, 24, 24, 64)        73792     \n",
            "_________________________________________________________________\n",
            "conv2d_1212 (Conv2D)         (None, 20, 20, 1)         1601      \n",
            "=================================================================\n",
            "Total params: 85,889\n",
            "Trainable params: 85,889\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.00613, saving model to SRCNN_check935.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(None, Non..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(3, 3), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00002: val_loss improved from 0.00613 to 0.00412, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.00412 to 0.00289, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.00289 to 0.00220, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00220 to 0.00196, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00196 to 0.00182, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00182 to 0.00166, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00166 to 0.00157, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00157 to 0.00152, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00152 to 0.00148, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00148 to 0.00148, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00148 to 0.00144, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00144 to 0.00142, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00142 to 0.00142, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00142 to 0.00140, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00140 to 0.00139, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00139 to 0.00139, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00139 to 0.00138, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00138 to 0.00138, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00138\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.00138 to 0.00137, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.00137\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00137 to 0.00137, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00137 to 0.00136, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00136\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.00136 to 0.00136, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00136\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.00136 to 0.00135, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.00135 to 0.00135, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.00135 to 0.00135, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.00135 to 0.00135, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.00135 to 0.00134, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.00134\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.00134 to 0.00133, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.00133 to 0.00133, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.00133\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.00133 to 0.00133, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00133\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.00133 to 0.00132, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.00132 to 0.00132, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.00132 to 0.00132, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.00132 to 0.00131, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00053: val_loss improved from 0.00131 to 0.00131, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00057: val_loss improved from 0.00131 to 0.00130, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00060: val_loss improved from 0.00130 to 0.00130, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00061: val_loss improved from 0.00130 to 0.00130, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.00130 to 0.00130, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00069: val_loss improved from 0.00130 to 0.00130, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00072: val_loss improved from 0.00130 to 0.00129, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00074: val_loss improved from 0.00129 to 0.00129, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00078: val_loss improved from 0.00129 to 0.00129, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00088: val_loss improved from 0.00129 to 0.00128, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00092: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00093: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00099: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00104: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00105: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00115: val_loss improved from 0.00128 to 0.00127, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00123: val_loss improved from 0.00127 to 0.00127, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00145: val_loss improved from 0.00127 to 0.00127, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00148: val_loss improved from 0.00127 to 0.00127, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00159: val_loss improved from 0.00127 to 0.00126, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00175: val_loss improved from 0.00126 to 0.00126, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00187: val_loss improved from 0.00126 to 0.00126, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00192: val_loss improved from 0.00126 to 0.00126, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00198: val_loss improved from 0.00126 to 0.00126, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.00126\n",
            "[25.30405909799104, 27.737742283120557, 29.60643016811212, 30.77496671755111, 30.998759733482228, 31.51149811300193, 32.18134635546018, 32.23797742431363, 32.41950046574363, 32.482662593279315, 32.490787014064594, 32.92862622437907, 32.78900009096292, 32.77269729004279, 32.95369669543569, 33.01560031750032, 33.00665432970101, 33.20051601554202, 33.00271430592801, 33.00271430592801, 32.908197631235325, 32.908197631235325, 33.07972904979804, 32.98142950039022, 32.98142950039022, 33.2476019310379, 33.2476019310379, 33.00656005879159, 33.10358713083667, 33.10358713083667, 33.10358713083667, 33.13724407245628, 33.140292547230565, 33.140292547230565, 33.140292547230565, 32.91015965313714, 32.91015965313714, 33.15903220012763, 33.08448477796074, 33.08448477796074, 32.919214523925135, 32.919214523925135, 33.183088447582726, 33.39779576566748, 33.39779576566748, 33.39779576566748, 33.13840476606353, 33.13840476606353, 33.13840476606353, 32.94806456737984, 32.94806456737984, 32.94806456737984, 33.43980566305673, 33.43980566305673, 33.43980566305673, 33.43980566305673, 32.907718812492845, 32.907718812492845, 32.907718812492845, 33.45258822981757, 33.07989356553376, 33.323669295648045, 33.323669295648045, 33.323669295648045, 33.323669295648045, 33.323669295648045, 33.323669295648045, 33.323669295648045, 32.926763775413484, 32.926763775413484, 32.926763775413484, 33.32380940066422, 33.32380940066422, 33.47830656132352, 33.47830656132352, 33.47830656132352, 33.47830656132352, 33.19797089352489, 33.19797089352489, 33.19797089352489, 33.19797089352489, 33.19797089352489, 33.19797089352489, 33.19797089352489, 33.19797089352489, 33.19797089352489, 33.19797089352489, 33.280115552867926, 33.280115552867926, 33.280115552867926, 33.280115552867926, 33.37880862850796, 33.50715754927776, 33.50715754927776, 33.50715754927776, 33.50715754927776, 33.50715754927776, 33.50715754927776, 33.58300509723518, 33.58300509723518, 33.58300509723518, 33.58300509723518, 33.58300509723518, 33.550967722404366, 33.34116368265841, 33.34116368265841, 33.34116368265841, 33.34116368265841, 33.34116368265841, 33.34116368265841, 33.34116368265841, 33.34116368265841, 33.34116368265841, 33.34116368265841, 33.475689907735244, 33.475689907735244, 33.475689907735244, 33.475689907735244, 33.475689907735244, 33.475689907735244, 33.475689907735244, 33.475689907735244, 33.42847932390378, 33.42847932390378, 33.42847932390378, 33.42847932390378, 33.42847932390378, 33.42847932390378, 33.42847932390378, 33.42847932390378, 33.42847932390378, 33.42847932390378, 33.42847932390378, 33.42847932390378, 33.42847932390378, 33.42847932390378, 33.42847932390378, 33.42847932390378, 33.42847932390378, 33.42847932390378, 33.42847932390378, 33.42847932390378, 33.42847932390378, 33.42847932390378, 33.35637899347301, 33.35637899347301, 33.35637899347301, 33.19696939452156, 33.19696939452156, 33.19696939452156, 33.19696939452156, 33.19696939452156, 33.19696939452156, 33.19696939452156, 33.19696939452156, 33.19696939452156, 33.19696939452156, 33.19696939452156, 33.42829553486301, 33.42829553486301, 33.42829553486301, 33.42829553486301, 33.42829553486301, 33.42829553486301, 33.42829553486301, 33.42829553486301, 33.42829553486301, 33.42829553486301, 33.42829553486301, 33.42829553486301, 33.42829553486301, 33.42829553486301, 33.42829553486301, 33.42829553486301, 33.37454621970418, 33.37454621970418, 33.37454621970418, 33.37454621970418, 33.37454621970418, 33.37454621970418, 33.37454621970418, 33.37454621970418, 33.37454621970418, 33.37454621970418, 33.37454621970418, 33.37454621970418, 33.309430923443855, 33.309430923443855, 33.309430923443855, 33.309430923443855, 33.309430923443855, 33.338326311517505, 33.338326311517505, 33.338326311517505, 33.338326311517505, 33.338326311517505, 33.338326311517505, 33.5237259357926, 33.5237259357926, 33.5237259357926]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSiTc-iparFv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "51abf551-18db-41be-aaf9-967afe31709b"
      },
      "source": [
        "history955=PsnrHistory()\n",
        "\n",
        "\n",
        "train(history955,\"955\")\n",
        "print(history955.psnrs)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(32, 32, 1..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:67: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(5, 5), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 24, 24, 128)       10496     \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 24, 24, 64)        204864    \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 20, 20, 1)         1601      \n",
            "=================================================================\n",
            "Total params: 216,961\n",
            "Trainable params: 216,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.00522, saving model to SRCNN_check955.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:78: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(None, Non..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:80: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(5, 5), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:83: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00002: val_loss improved from 0.00522 to 0.00281, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.00281 to 0.00210, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.00210 to 0.00179, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00179 to 0.00174, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00174 to 0.00156, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00156 to 0.00149, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00149 to 0.00146, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00146 to 0.00143, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.00143\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00143 to 0.00141, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00141 to 0.00140, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00140 to 0.00139, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00139 to 0.00138, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.00138\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00138\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00138 to 0.00137, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00137 to 0.00136, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00136 to 0.00136, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00136\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.00136 to 0.00136, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.00136\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00136 to 0.00135, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.00135 to 0.00135, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.00135 to 0.00135, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.00135 to 0.00134, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00134\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00134\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.00134 to 0.00133, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00133\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.00133 to 0.00132, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.00132 to 0.00132, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.00132 to 0.00132, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.00132 to 0.00132, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.00132 to 0.00131, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.00131 to 0.00130, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.00130 to 0.00130, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00055: val_loss improved from 0.00130 to 0.00130, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00057: val_loss improved from 0.00130 to 0.00129, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00067: val_loss improved from 0.00129 to 0.00129, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00068: val_loss improved from 0.00129 to 0.00129, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00072: val_loss improved from 0.00129 to 0.00128, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00077: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00079: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00084: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00086: val_loss improved from 0.00128 to 0.00127, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00102: val_loss improved from 0.00127 to 0.00127, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00103: val_loss improved from 0.00127 to 0.00127, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00110: val_loss improved from 0.00127 to 0.00126, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00123: val_loss improved from 0.00126 to 0.00126, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.00126\n",
            "[25.610316595140095, 29.465067632624375, 30.523223127844847, 31.382302310352372, 30.473549256535374, 32.169566313943136, 32.31926108293673, 32.51827219877256, 32.70721386836711, 32.70721386836711, 32.45149331703297, 32.563354963491605, 32.877269154512746, 32.701183633677914, 32.701183633677914, 32.701183633677914, 32.82738854572353, 32.954231302426294, 32.7004710341897, 32.7004710341897, 32.9315902586437, 32.9315902586437, 33.016726099245766, 33.016726099245766, 32.99556631257563, 32.966325833792844, 32.966325833792844, 32.966325833792844, 33.02179368064738, 33.02179368064738, 33.02179368064738, 32.766019356327625, 32.766019356327625, 33.10274130704294, 33.10274130704294, 33.10274130704294, 33.10274130704294, 32.85998955877015, 33.03416267645821, 33.1034674956221, 33.232022326784616, 33.232022326784616, 33.232022326784616, 33.232022326784616, 33.232022326784616, 33.1042987717281, 33.1042987717281, 33.1042987717281, 33.1042987717281, 33.1042987717281, 33.1042987717281, 33.1042987717281, 33.1042987717281, 33.081557356205984, 33.00312750041833, 33.00312750041833, 33.07162351954462, 33.07162351954462, 33.07162351954462, 33.07162351954462, 33.07162351954462, 33.07162351954462, 33.07162351954462, 33.07162351954462, 33.07162351954462, 33.07162351954462, 33.23873466176376, 32.99004366391075, 32.99004366391075, 32.99004366391075, 32.99004366391075, 33.22177992611107, 33.22177992611107, 33.22177992611107, 33.22177992611107, 33.22177992611107, 33.156511913330604, 33.156511913330604, 33.198124920788814, 33.198124920788814, 33.198124920788814, 33.198124920788814, 33.198124920788814, 33.29503579604503, 33.29503579604503, 33.19844943481608, 33.19844943481608, 33.19844943481608, 33.19844943481608, 33.19844943481608, 33.19844943481608, 33.19844943481608, 33.19844943481608, 33.19844943481608, 33.19844943481608, 33.19844943481608, 33.19844943481608, 33.19844943481608, 33.19844943481608, 33.19844943481608, 33.19844943481608, 33.15396329361238, 33.27139606293105, 33.27139606293105, 33.27139606293105, 33.27139606293105, 33.27139606293105, 33.27139606293105, 33.27139606293105, 33.32918854971041, 33.32918854971041, 33.32918854971041, 33.32918854971041, 33.32918854971041, 33.32918854971041, 33.32918854971041, 33.32918854971041, 33.32918854971041, 33.32918854971041, 33.32918854971041, 33.32918854971041, 33.32918854971041, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136, 33.14228892724136]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU4Y1ywhlAot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(architecture,file_name):\n",
        "    if architecture==\"915\":\n",
        "      srcnn_model = predict_model915()\n",
        "    elif architecture==\"935\":\n",
        "      srcnn_model=predict_model935()\n",
        "    else:\n",
        "      srcnn_model=predict_model955()\n",
        "    weight_file=\"SRCNN_check\"+architecture+\".h5\" \n",
        "    srcnn_model.load_weights(weight_file)\n",
        "    IMG_NAME = file_name\n",
        "    INPUT_NAME = \"Input to the \"+architecture+\".png\"\n",
        "    OUTPUT_NAME = \"Output of the\"+architecture+\".png\"\n",
        "\n",
        "    import cv2\n",
        "    img = cv2.imread(IMG_NAME, cv2.IMREAD_COLOR)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
        "    shape = img.shape\n",
        "    Y_img = cv2.resize(img[:, :, 0], (int(shape[1] / 2), int(shape[0] / 2)), cv2.INTER_CUBIC)\n",
        "    Y_img = cv2.resize(Y_img, (shape[1], shape[0]), cv2.INTER_CUBIC)\n",
        "    print(img.shape,Y_img.shape)\n",
        "    img[:, :, 0] = Y_img\n",
        "    Y_img=img[:,:,0]\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_YCrCb2BGR)\n",
        "    cv2.imwrite(INPUT_NAME, img)\n",
        "\n",
        "    Y = numpy.zeros((1, img.shape[0], img.shape[1], 1), dtype=float)\n",
        "    Y[0, :, :, 0] = Y_img.astype(float) / 255.\n",
        "    pre = srcnn_model.predict(Y, batch_size=1) * 255.\n",
        "    print(pre.shape)\n",
        "    pre[pre[:] > 255] = 255\n",
        "    pre[pre[:] < 0] = 0\n",
        "    pre = pre.astype(numpy.uint8)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
        "    img[6: -6, 6: -6, 0] = pre[0, :, :, 0]\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_YCrCb2BGR)\n",
        "    print(img.shape)\n",
        "    cv2.imwrite(OUTPUT_NAME, img)\n",
        "\n",
        "    # psnr calculation:\n",
        "    im1_rgb = cv2.imread(IMG_NAME, cv2.IMREAD_COLOR)[6: -6, 6: -6, :]\n",
        "    im1_Y = cv2.cvtColor(im1_rgb, cv2.COLOR_BGR2YCrCb)\n",
        "    im2_rgb = cv2.imread(INPUT_NAME, cv2.IMREAD_COLOR)[6: -6, 6: -6, :]\n",
        "    im2_Y = cv2.cvtColor(im2_rgb, cv2.COLOR_BGR2YCrCb)\n",
        "    im3_rgb = cv2.imread(OUTPUT_NAME, cv2.IMREAD_COLOR)[6: -6, 6: -6, :]\n",
        "    im3_Y = cv2.cvtColor(im3_rgb, cv2.COLOR_BGR2YCrCb)\n",
        "    print(im3_Y.shape,im1_Y.shape)\n",
        "    print(\"bicubic:\")\n",
        "    print(\"YCrCCb= {} , RGB={}\".format(psnr(im1_Y[:,:,0],im2_Y[:,:,0]),psnr(im1_rgb,im2_rgb)))\n",
        "    print(\"SRCNN:\")\n",
        "    print(\"YCrCCb= {} , RGB={}\".format(psnr(im1_Y[:,:,0],im3_Y[:,:,0]),psnr(im1_rgb,im3_rgb)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87FeW85u8L7c",
        "colab_type": "code",
        "outputId": "0cf40493-f902-4822-800a-2d0a565dfafb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "\n",
        "import numpy\n",
        "x1=numpy.linspace(1,len(history915.psnrs),len(history915.psnrs))\n",
        "y1 = numpy.asarray(history915.psnrs, dtype=numpy.float32)\n",
        "x2=numpy.linspace(1,len(history935.psnrs),len(history935.psnrs))\n",
        "y2 = numpy.asarray(history935.psnrs, dtype=numpy.float32)\n",
        "x3=numpy.linspace(1,len(history955.psnrs),len(history955.psnrs))\n",
        "y3 = numpy.asarray(history955.psnrs, dtype=numpy.float32)\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(x1,y1, '-b', label='9-1-5')\n",
        "ax.plot(x2,y2, '-r', label='9-3-5')\n",
        "ax.plot(x3,y3,'-g',label='9-5-5')\n",
        "\n",
        "leg = ax.legend();\n",
        "\n",
        "plt.show(fig)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD6CAYAAAC4RRw1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/T/VQ7sIlLA5rwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58XNJ9mMDjF8",
        "colab_type": "code",
        "outputId": "d2a4093c-a3e1-481b-fa41-db7e170117c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "predict(\"915\",\"butterfly.png\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(None, Non..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(1, 1), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(256, 256, 3) (256, 256)\n",
            "(1, 244, 244, 1)\n",
            "(256, 256, 3)\n",
            "(244, 244, 3) (244, 244, 3)\n",
            "bicubic:\n",
            "YCrCCb= 32.053059313091204 , RGB=32.021477707251755\n",
            "SRCNN:\n",
            "YCrCCb= 33.26462712748934 , RGB=33.23101516696309\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXmcq3LSH5Oo",
        "colab_type": "code",
        "outputId": "8c83dd53-5d21-4795-c32b-d0b4a1d3dc84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "predict(\"935\",\"butterfly.png\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(None, Non..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(3, 3), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(256, 256, 3) (256, 256)\n",
            "(1, 244, 244, 1)\n",
            "(256, 256, 3)\n",
            "(244, 244, 3) (244, 244, 3)\n",
            "bicubic:\n",
            "YCrCCb= 32.053059313091204 , RGB=32.021477707251755\n",
            "SRCNN:\n",
            "YCrCCb= 33.41284379396767 , RGB=33.384681629630954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi8onmLIH5X0",
        "colab_type": "code",
        "outputId": "e281f992-258f-42fc-e4ff-c0878ee44260",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "predict(\"955\",\"butterfly.png\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:78: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(None, Non..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:80: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(5, 5), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:83: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(256, 256, 3) (256, 256)\n",
            "(1, 244, 244, 1)\n",
            "(256, 256, 3)\n",
            "(244, 244, 3) (244, 244, 3)\n",
            "bicubic:\n",
            "YCrCCb= 32.053059313091204 , RGB=32.021477707251755\n",
            "SRCNN:\n",
            "YCrCCb= 33.321346307427504 , RGB=33.290039628015194\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}