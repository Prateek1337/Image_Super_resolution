{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageResFilterExperiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prateek1337/Image_Super_resolution/blob/master/ImageResFilterExperiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTLHSmW23asG",
        "colab_type": "code",
        "outputId": "b5b33831-3b4d-475d-a6f2-bbf9068dbf0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV7UDX6B3q7P",
        "colab_type": "code",
        "outputId": "9ba2d564-610b-4018-de2e-99248d35dabc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "import os \n",
        "os.chdir(\"/content/drive/My Drive/Image_Resolution/\")\n",
        "os.getcwd()\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "butterfly.png\t   SRCNN_check935BSDS200.h5  testFinal.h5\n",
            "face.png\t   SRCNN_check935G100.h5     test.h5\n",
            "prepare_data.py    SRCNN_check935.h5\t     trainFinalBSDS200.h5\n",
            "__pycache__\t   SRCNN_check935T91.h5      trainFinalG100.h5\n",
            "SRCNN_check915.h5  SRCNN_check955.h5\t     trainFinalT91.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk6-ZqmZ4bTg",
        "colab_type": "code",
        "outputId": "e992a4ef-15a9-4df8-ecc2-544c92bd0679",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "from keras import initializers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Input, BatchNormalization\n",
        "# from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.callbacks import ModelCheckpoint,Callback\n",
        "from keras.optimizers import SGD, Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import prepare_data as pd\n",
        "import numpy \n",
        "import math\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ninR1LjWtT29",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#setting seed for uniform results\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG0RN41fY1pk",
        "colab_type": "code",
        "outputId": "caabb9e9-0349-4e9d-fc03-31c98f79f526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data_Y, label_Y = pd.read_training_data(\"./testFinal.h5\")\n",
        "print(data_Y.shape,label_Y.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(420, 32, 32, 1) (420, 20, 20, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g-jFwan61pN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#9-1-5 Architecture \n",
        "def model915():\n",
        "    # lrelu = LeakyReLU(alpha=0.1)\n",
        "    SRCNN = Sequential()\n",
        "    SRCNN.add(Conv2D(nb_filter=128, nb_row=9, nb_col=9, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='valid', bias=True, input_shape=(32, 32, 1)))\n",
        "    SRCNN.add(Conv2D(nb_filter=64, nb_row=1, nb_col=1, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='same', bias=True))\n",
        "    # SRCNN.add(BatchNormalization())\n",
        "    SRCNN.add(Conv2D(nb_filter=1, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='linear', border_mode='valid', bias=True))\n",
        "    adam = Adam(lr=0.0003)\n",
        "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return SRCNN\n",
        "def predict_model915():\n",
        "    # lrelu = LeakyReLU(alpha=0.1)\n",
        "    SRCNN = Sequential()\n",
        "    SRCNN.add(Conv2D(nb_filter=128, nb_row=9, nb_col=9, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='valid', bias=True, input_shape=(None, None, 1)))\n",
        "    SRCNN.add(Conv2D(nb_filter=64, nb_row=1, nb_col=1, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='same', bias=True))\n",
        "    # SRCNN.add(BatchNormalization())\n",
        "    SRCNN.add(Conv2D(nb_filter=1, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='linear', border_mode='valid', bias=True))\n",
        "    adam = Adam(lr=0.0003)\n",
        "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return SRCNN\n",
        "\n",
        " \n",
        " \n",
        "#9-3-5 Architecture \n",
        "def model935():\n",
        "    # lrelu = LeakyReLU(alpha=0.1)\n",
        "    SRCNN = Sequential()\n",
        "    SRCNN.add(Conv2D(nb_filter=128, nb_row=9, nb_col=9, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='valid', bias=True, input_shape=(32, 32, 1)))\n",
        "    SRCNN.add(Conv2D(nb_filter=64, nb_row=3, nb_col=3, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='same', bias=True))\n",
        "    # SRCNN.add(BatchNormalization())\n",
        "    SRCNN.add(Conv2D(nb_filter=1, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='linear', border_mode='valid', bias=True))\n",
        "    adam = Adam(lr=0.0003)\n",
        "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return SRCNN\n",
        "def predict_model935():\n",
        "    # lrelu = LeakyReLU(alpha=0.1)\n",
        "    SRCNN = Sequential()\n",
        "    SRCNN.add(Conv2D(nb_filter=128, nb_row=9, nb_col=9, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='valid', bias=True, input_shape=(None, None, 1)))\n",
        "    SRCNN.add(Conv2D(nb_filter=64, nb_row=3, nb_col=3, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='same', bias=True))\n",
        "    # SRCNN.add(BatchNormalization())\n",
        "    SRCNN.add(Conv2D(nb_filter=1, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='linear', border_mode='valid', bias=True))\n",
        "    adam = Adam(lr=0.0003)\n",
        "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return SRCNN\n",
        "\n",
        "\n",
        " \n",
        "#9-5-5 Architecture \n",
        "def model955():\n",
        "    # lrelu = LeakyReLU(alpha=0.1)\n",
        "    SRCNN = Sequential()\n",
        "    SRCNN.add(Conv2D(nb_filter=128, nb_row=9, nb_col=9, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='valid', bias=True, input_shape=(32, 32, 1)))\n",
        "    SRCNN.add(Conv2D(nb_filter=64, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='same', bias=True))\n",
        "    # SRCNN.add(BatchNormalization())\n",
        "    SRCNN.add(Conv2D(nb_filter=1, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='linear', border_mode='valid', bias=True))\n",
        "    adam = Adam(lr=0.0003)\n",
        "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return SRCNN\n",
        "def predict_model955():\n",
        "    # lrelu = LeakyReLU(alpha=0.1)\n",
        "    SRCNN = Sequential()\n",
        "    SRCNN.add(Conv2D(nb_filter=128, nb_row=9, nb_col=9, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='valid', bias=True, input_shape=(None, None, 1)))\n",
        "    SRCNN.add(Conv2D(nb_filter=64, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='same', bias=True))\n",
        "    # SRCNN.add(BatchNormalization())\n",
        "    SRCNN.add(Conv2D(nb_filter=1, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='linear', border_mode='valid', bias=True))\n",
        "    adam = Adam(lr=0.0003)\n",
        "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return SRCNN\n",
        "\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOy6MsaDj1KS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def psnr(target, ref):\n",
        "    mse = numpy.mean( (target - ref) ** 2 )\n",
        "    PIXEL_MAX = 255.0\n",
        "    if mse == 0:\n",
        "        return 100\n",
        "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
        "\n",
        "\n",
        "\n",
        "class PsnrHistory(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.psnrs = []\n",
        "        \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        global modelArc\n",
        "        if modelArc==\"955\":\n",
        "          srcnn_model=predict_model955()\n",
        "          weights_file=\"SRCNN_check955.h5\"\n",
        "        elif modelArc==\"935\":\n",
        "          srcnn_model=predict_model935()\n",
        "          weights_file=\"SRCNN_check935.h5\"\n",
        "        elif modelArc==\"915\":\n",
        "          srcnn_model=predict_model915()\n",
        "          weights_file=\"SRCNN_check915.h5\"\n",
        "        srcnn_model.load_weights(weights_file)\n",
        "        avg_psnr=0.0\n",
        "        import cv2\n",
        "        for i in range(0,data_Y.shape[0]):\n",
        "            img=data_Y[i]\n",
        "            Y = numpy.zeros((1, img.shape[0], img.shape[1], 1), dtype=float)\n",
        "            Y[0, :, :, :] = img\n",
        "            pre = srcnn_model.predict(Y, batch_size=1) * 255.\n",
        "            pre[pre[:] > 255] = 255\n",
        "            pre[pre[:] < 0] = 0\n",
        "            img_pre=pre[0,:,:,:]\n",
        "            avg_psnr=avg_psnr+psnr(label_Y[i]*255, img_pre)\n",
        "\n",
        "        avg_psnr=(avg_psnr/data_Y.shape[0])\n",
        "        \n",
        "        self.psnrs.append((avg_psnr))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhRytvFCm-Eq",
        "colab_type": "code",
        "outputId": "c3b5982b-bce4-43d1-9e50-0dec77a854ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#TPU EXPERIMENTATION TRY LATER\n",
        "try:\n",
        "  device_name = os.environ['COLAB_TPU_ADDR']\n",
        "  TPU_ADDRESS = 'grpc://' + device_name\n",
        "  print('Found TPU at: {}'.format(TPU_ADDRESS))\n",
        "\n",
        "except KeyError:\n",
        "  print('TPU not found')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy9tcl-clzp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TPU EXPERIMENTATION TRY LATER\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "tpu_model915 = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model915,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(\n",
        "            tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "    )\n",
        ")\n",
        "tpu_model935 = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model935,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(\n",
        "            tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "    )\n",
        ")\n",
        "tpu_model955 = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model955,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(\n",
        "            tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "    )\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBbPfb1Zj2ha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(history,arch):\n",
        "    \n",
        "    if arch==\"915\":\n",
        "      srcnn_model = model915()\n",
        "    elif arch==\"935\":\n",
        "      srcnn_model=model935()\n",
        "      \n",
        "    else:\n",
        "      srcnn_model=model955()\n",
        "      \n",
        "    print(srcnn_model.summary())\n",
        "    data, label = pd.read_training_data(\"./trainFinalT91.h5\")\n",
        "    val_data, val_label = pd.read_training_data(\"./testFinal.h5\")\n",
        "    global modelArc\n",
        "    modelArc=arch\n",
        "    h5File=\"SRCNN_check\"+arch+\".h5\"\n",
        "    checkpoint = ModelCheckpoint(h5File, monitor='val_loss', verbose=1, save_best_only=True,\n",
        "                                 save_weights_only=False, mode='min')\n",
        "    callbacks_list = [checkpoint,history]\n",
        "\n",
        "    srcnn_model.fit(data, label, batch_size=128, validation_data=(val_data, val_label),\n",
        "                    callbacks=callbacks_list, shuffle=True, nb_epoch=200, verbose=0)\n",
        "    # srcnn_model.load_weights(\"m_model_adam.h5\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0EjckXcwdTG",
        "colab_type": "code",
        "outputId": "6288cca7-605f-49dc-c953-fcd2e01d8be1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history915=PsnrHistory()\n",
        "\n",
        "\n",
        "train(history915,\"915\")\n",
        "print(\"Final Psnr:\",history915.psnrs[-1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 128)       10496     \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        8256      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 20, 20, 1)         1601      \n",
            "=================================================================\n",
            "Total params: 20,353\n",
            "Trainable params: 20,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(32, 32, 1..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(1, 1), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.00278, saving model to SRCNN_check915.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(None, Non..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(1, 1), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00002: val_loss improved from 0.00278 to 0.00199, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.00199 to 0.00175, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.00175 to 0.00162, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00162 to 0.00155, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00155 to 0.00152, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00152 to 0.00149, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00149 to 0.00146, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00146 to 0.00144, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00144 to 0.00143, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00143 to 0.00141, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00141 to 0.00140, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.00140\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00140 to 0.00138, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00138 to 0.00138, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00138\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00138 to 0.00137, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00137 to 0.00137, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.00137\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.00137 to 0.00136, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.00136 to 0.00136, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00136 to 0.00136, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00136 to 0.00135, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00135 to 0.00135, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00135\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.00135 to 0.00134, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.00134 to 0.00134, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00134\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.00134\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.00134 to 0.00134, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.00134 to 0.00134, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.00134 to 0.00134, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.00134 to 0.00132, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.00132 to 0.00132, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.00132 to 0.00131, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.00131 to 0.00131, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.00131 to 0.00130, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.00130 to 0.00130, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.00130 to 0.00130, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.00130\n",
            "\n",
            "Epoch 00051: val_loss improved from 0.00130 to 0.00130, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00052: val_loss improved from 0.00130 to 0.00129, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.00129 to 0.00129, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00056: val_loss improved from 0.00129 to 0.00128, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00061: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00063: val_loss improved from 0.00128 to 0.00127, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00064: val_loss improved from 0.00127 to 0.00127, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00065: val_loss improved from 0.00127 to 0.00127, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00070: val_loss improved from 0.00127 to 0.00127, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00071: val_loss improved from 0.00127 to 0.00126, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00078: val_loss improved from 0.00126 to 0.00126, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00085: val_loss improved from 0.00126 to 0.00125, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00090: val_loss improved from 0.00125 to 0.00125, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00094: val_loss improved from 0.00125 to 0.00125, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00098: val_loss improved from 0.00125 to 0.00125, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00104: val_loss improved from 0.00125 to 0.00124, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00106: val_loss improved from 0.00124 to 0.00124, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00108: val_loss improved from 0.00124 to 0.00124, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00110: val_loss improved from 0.00124 to 0.00123, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00127: val_loss improved from 0.00123 to 0.00123, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00136: val_loss improved from 0.00123 to 0.00122, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00171: val_loss improved from 0.00122 to 0.00122, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00193: val_loss improved from 0.00122 to 0.00122, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00194: val_loss improved from 0.00122 to 0.00122, saving model to SRCNN_check915.h5\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.00122\n",
            "Final Psnr: 33.65321190322345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAJr8VdLaqjC",
        "colab_type": "code",
        "outputId": "041b4ccc-224f-4789-cf4a-e69cac430b83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history935=PsnrHistory()\n",
        "\n",
        "\n",
        "train(history935,\"935\")\n",
        "print(\"Final Psnr:\",history935.psnrs[-1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_202\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_604 (Conv2D)          (None, 24, 24, 128)       10496     \n",
            "_________________________________________________________________\n",
            "conv2d_605 (Conv2D)          (None, 24, 24, 64)        73792     \n",
            "_________________________________________________________________\n",
            "conv2d_606 (Conv2D)          (None, 20, 20, 1)         1601      \n",
            "=================================================================\n",
            "Total params: 85,889\n",
            "Trainable params: 85,889\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(32, 32, 1..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(3, 3), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.00257, saving model to SRCNN_check935.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(None, Non..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(3, 3), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00002: val_loss improved from 0.00257 to 0.00167, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.00167 to 0.00151, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.00151 to 0.00145, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00145 to 0.00141, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00141 to 0.00140, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00140 to 0.00138, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.00138\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00138 to 0.00137, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00137 to 0.00135, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00135 to 0.00135, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00135 to 0.00134, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.00134\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00134 to 0.00134, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00134 to 0.00132, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00132\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00132 to 0.00131, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00131 to 0.00131, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.00131 to 0.00129, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.00129 to 0.00128, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.00128 to 0.00127, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.00127 to 0.00126, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00126\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.00126 to 0.00125, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00052: val_loss improved from 0.00125 to 0.00124, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00058: val_loss improved from 0.00124 to 0.00124, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00060: val_loss improved from 0.00124 to 0.00124, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00066: val_loss improved from 0.00124 to 0.00123, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00069: val_loss improved from 0.00123 to 0.00123, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00074: val_loss improved from 0.00123 to 0.00123, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00081: val_loss improved from 0.00123 to 0.00123, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00083: val_loss improved from 0.00123 to 0.00123, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00088: val_loss improved from 0.00123 to 0.00122, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00093: val_loss improved from 0.00122 to 0.00122, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00095: val_loss improved from 0.00122 to 0.00122, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.00122\n",
            "\n",
            "Epoch 00104: val_loss improved from 0.00122 to 0.00121, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00123: val_loss improved from 0.00121 to 0.00120, saving model to SRCNN_check935.h5\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.00120\n",
            "Final Psnr: 33.58185781511587\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSiTc-iparFv",
        "colab_type": "code",
        "outputId": "371f39e9-ab23-4b17-e249-a27191d486e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history955=PsnrHistory()\n",
        "\n",
        "\n",
        "train(history955,\"955\")\n",
        "print(\"Final Psnr:\",history955.psnrs)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_403\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1207 (Conv2D)         (None, 24, 24, 128)       10496     \n",
            "_________________________________________________________________\n",
            "conv2d_1208 (Conv2D)         (None, 24, 24, 64)        204864    \n",
            "_________________________________________________________________\n",
            "conv2d_1209 (Conv2D)         (None, 20, 20, 1)         1601      \n",
            "=================================================================\n",
            "Total params: 216,961\n",
            "Trainable params: 216,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(32, 32, 1..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:67: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(5, 5), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.00190, saving model to SRCNN_check955.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:78: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(None, Non..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:80: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(5, 5), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:83: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00002: val_loss improved from 0.00190 to 0.00151, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.00151 to 0.00143, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.00143 to 0.00141, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00141 to 0.00138, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00138 to 0.00137, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00137 to 0.00136, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00136 to 0.00135, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00135 to 0.00134, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00134 to 0.00134, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00134 to 0.00133, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.00133\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00133 to 0.00132, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00132 to 0.00132, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00132 to 0.00132, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00132 to 0.00129, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00129 to 0.00129, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00129\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.00129 to 0.00129, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00129 to 0.00128, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00128\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.00128 to 0.00127, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00127\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.00127 to 0.00125, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.00125 to 0.00125, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.00125 to 0.00125, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.00125\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.00125 to 0.00124, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.00124 to 0.00124, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.00124 to 0.00123, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.00123\n",
            "\n",
            "Epoch 00053: val_loss improved from 0.00123 to 0.00121, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00060: val_loss improved from 0.00121 to 0.00121, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.00121 to 0.00121, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.00121\n",
            "\n",
            "Epoch 00072: val_loss improved from 0.00121 to 0.00120, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.00120\n",
            "\n",
            "Epoch 00074: val_loss improved from 0.00120 to 0.00119, saving model to SRCNN_check955.h5\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.00119\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.00119\n",
            "Final Psnr: [31.24546874510225, 32.458094317130225, 32.666421350439364, 32.60883948709795, 32.99101082219185, 33.012356528528386, 33.07524692737341, 33.004407453477334, 33.03579065746974, 33.023803626309615, 33.03890522339714, 33.03890522339714, 33.26402517985902, 33.15818644412839, 33.0826253788204, 33.25557565774796, 33.25557565774796, 33.25557565774796, 33.20246463950556, 33.20246463950556, 33.15001013299576, 33.28270743623509, 33.28270743623509, 33.28270743623509, 33.28270743623509, 33.33344970390346, 33.33344970390346, 33.33344970390346, 33.35269562622919, 33.35269562622919, 33.35269562622919, 33.35269562622919, 33.35269562622919, 33.47269900877398, 33.34664781279774, 33.34664781279774, 33.34664781279774, 33.34664781279774, 33.34664781279774, 33.29770169801788, 33.29770169801788, 33.29770169801788, 33.29770169801788, 33.29770169801788, 33.29770169801788, 33.29770169801788, 33.43301472808335, 33.43301472808335, 33.43301472808335, 33.4002132260226, 33.4002132260226, 33.4002132260226, 33.693735538936146, 33.693735538936146, 33.693735538936146, 33.693735538936146, 33.693735538936146, 33.693735538936146, 33.693735538936146, 33.52660143980083, 33.52660143980083, 33.553456540444124, 33.553456540444124, 33.553456540444124, 33.553456540444124, 33.553456540444124, 33.553456540444124, 33.553456540444124, 33.553456540444124, 33.553456540444124, 33.553456540444124, 33.441549026983125, 33.441549026983125, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936, 33.663844214269936]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU4Y1ywhlAot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(architecture,file_name):\n",
        "    if architecture==\"915\":\n",
        "      srcnn_model = predict_model915()\n",
        "    elif architecture==\"935\":\n",
        "      srcnn_model=predict_model935()\n",
        "    else:\n",
        "      srcnn_model=predict_model955()\n",
        "    weight_file=\"SRCNN_check\"+architecture+\".h5\" \n",
        "    srcnn_model.load_weights(weight_file)\n",
        "    IMG_NAME = file_name\n",
        "    INPUT_NAME = \"Input to the \"+architecture+\".png\"\n",
        "    OUTPUT_NAME = \"Output of the\"+architecture+\".png\"\n",
        "\n",
        "    import cv2\n",
        "    img = cv2.imread(IMG_NAME, cv2.IMREAD_COLOR)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
        "    shape = img.shape\n",
        "    Y_img = cv2.resize(img[:, :, 0], (int(shape[1] / 2), int(shape[0] / 2)), cv2.INTER_CUBIC)\n",
        "    Y_img = cv2.resize(Y_img, (shape[1], shape[0]), cv2.INTER_CUBIC)\n",
        "    print(img.shape,Y_img.shape)\n",
        "    img[:, :, 0] = Y_img\n",
        "    Y_img=img[:,:,0]\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_YCrCb2BGR)\n",
        "    cv2.imwrite(INPUT_NAME, img)\n",
        "\n",
        "    Y = numpy.zeros((1, img.shape[0], img.shape[1], 1), dtype=float)\n",
        "    Y[0, :, :, 0] = Y_img.astype(float) / 255.\n",
        "    pre = srcnn_model.predict(Y, batch_size=1) * 255.\n",
        "    print(pre.shape)\n",
        "    pre[pre[:] > 255] = 255\n",
        "    pre[pre[:] < 0] = 0\n",
        "    pre = pre.astype(numpy.uint8)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
        "    img[6: -6, 6: -6, 0] = pre[0, :, :, 0]\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_YCrCb2BGR)\n",
        "    print(img.shape)\n",
        "    cv2.imwrite(OUTPUT_NAME, img)\n",
        "\n",
        "    # psnr calculation:\n",
        "    im1_rgb = cv2.imread(IMG_NAME, cv2.IMREAD_COLOR)[6: -6, 6: -6, :]\n",
        "    im1_Y = cv2.cvtColor(im1_rgb, cv2.COLOR_BGR2YCrCb)\n",
        "    im2_rgb = cv2.imread(INPUT_NAME, cv2.IMREAD_COLOR)[6: -6, 6: -6, :]\n",
        "    im2_Y = cv2.cvtColor(im2_rgb, cv2.COLOR_BGR2YCrCb)\n",
        "    im3_rgb = cv2.imread(OUTPUT_NAME, cv2.IMREAD_COLOR)[6: -6, 6: -6, :]\n",
        "    im3_Y = cv2.cvtColor(im3_rgb, cv2.COLOR_BGR2YCrCb)\n",
        "    print(im3_Y.shape,im1_Y.shape)\n",
        "    print(\"bicubic:\")\n",
        "    print(\"YCrCCb= {} , RGB={}\".format(psnr(im1_Y[:,:,0],im2_Y[:,:,0]),psnr(im1_rgb,im2_rgb)))\n",
        "    print(\"SRCNN:\")\n",
        "    print(\"YCrCCb= {} , RGB={}\".format(psnr(im1_Y[:,:,0],im3_Y[:,:,0]),psnr(im1_rgb,im3_rgb)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87FeW85u8L7c",
        "colab_type": "code",
        "outputId": "98219dfd-1c1a-4d6b-ae4f-04b8ef563791",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "\n",
        "import numpy\n",
        "x1=numpy.linspace(1,len(history915.psnrs),len(history915.psnrs))\n",
        "y1 = numpy.asarray(history915.psnrs, dtype=numpy.float32)\n",
        "x2=numpy.linspace(1,len(history935.psnrs),len(history935.psnrs))\n",
        "y2 = numpy.asarray(history935.psnrs, dtype=numpy.float32)\n",
        "x3=numpy.linspace(1,len(history955.psnrs),len(history955.psnrs))\n",
        "y3 = numpy.asarray(history955.psnrs, dtype=numpy.float32)\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(x1,y1, '-b', label='9-1-5')\n",
        "ax.plot(x2,y2, '-r', label='9-3-5')\n",
        "ax.plot(x3,y3,'-g',label='9-5-5')\n",
        "\n",
        "leg = ax.legend();\n",
        "\n",
        "plt.show(fig)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD7CAYAAABkO19ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfM4CvTHG+JwFemOM8bn/D639iICW2H0wAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irtkVjmus_0j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "579808d5-c906-4a6b-e5bb-848fb2495083"
      },
      "source": [
        "x1=numpy.linspace(100,len(history915.psnrs),100)\n",
        "y1 = numpy.asarray(history915.psnrs[100:], dtype=numpy.float32)\n",
        "x2=numpy.linspace(100,len(history935.psnrs),100)\n",
        "y2 = numpy.asarray(history935.psnrs[100:], dtype=numpy.float32)\n",
        "x3=numpy.linspace(100,len(history955.psnrs),100)\n",
        "y3 = numpy.asarray(history955.psnrs[100:], dtype=numpy.float32)\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(x1,y1, '-b', label='9-1-5')\n",
        "ax.plot(x2,y2, '-r', label='9-3-5')\n",
        "ax.plot(x3,y3,'-g',label='9-5-5')\n",
        "\n",
        "leg = ax.legend();\n",
        "plt.title(\"Last 100 Epochs\")\n",
        "plt.show(fig)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58XNJ9mMDjF8",
        "colab_type": "code",
        "outputId": "cbd122cb-d963-4f9f-a8e1-302733ae8891",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "predict(\"915\",\"butterfly.png\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(None, Non..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(1, 1), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(256, 256, 3) (256, 256)\n",
            "(1, 244, 244, 1)\n",
            "(256, 256, 3)\n",
            "(244, 244, 3) (244, 244, 3)\n",
            "bicubic:\n",
            "YCrCCb= 32.053059313091204 , RGB=32.021477707251755\n",
            "SRCNN:\n",
            "YCrCCb= 33.56075266205568 , RGB=33.522776198406675\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXmcq3LSH5Oo",
        "colab_type": "code",
        "outputId": "08b1b351-077f-4997-f7d3-0c26a9de45d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "predict(\"935\",\"butterfly.png\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(None, Non..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(3, 3), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(256, 256, 3) (256, 256)\n",
            "(1, 244, 244, 1)\n",
            "(256, 256, 3)\n",
            "(244, 244, 3) (244, 244, 3)\n",
            "bicubic:\n",
            "YCrCCb= 32.053059313091204 , RGB=32.021477707251755\n",
            "SRCNN:\n",
            "YCrCCb= 33.68691645424939 , RGB=33.664502969103594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi8onmLIH5X0",
        "colab_type": "code",
        "outputId": "46f3dba5-e0ff-45e8-f245-fcaa330c3d6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "predict(\"955\",\"butterfly.png\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:78: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(None, Non..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:80: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(5, 5), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:83: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(256, 256, 3) (256, 256)\n",
            "(1, 244, 244, 1)\n",
            "(256, 256, 3)\n",
            "(244, 244, 3) (244, 244, 3)\n",
            "bicubic:\n",
            "YCrCCb= 32.053059313091204 , RGB=32.021477707251755\n",
            "SRCNN:\n",
            "YCrCCb= 33.616639192529114 , RGB=33.59013611316908\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}